{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inundation History Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool is used for associating river flow rates with Landsat and Sentinel satellite passes which are accessed through [Google Earth Engine](https://developers.google.com/earth-engine). It filters satellite passes within defined flow bands of interest, removes cloudy imagery, and also applies a filter to those images on the rising/falling limb. The images are then indexed using the MNDWI, NDWI, Fisher index and a custom False colour (swir2, nir and red) index for water identification.\n",
    "\n",
    "The tool outputs the images as Geotiff files to Google Cloud, Google Drive or as an Asset for use in GIS software (see [Exporting Data](https://developers.google.com/earth-engine/guides/exporting) user guide).\n",
    "\n",
    "> **Note:** To use this notebook you will need the have a Google Earth Engine account, subject to their [Terms and Conditons](https://earthengine.google.com/terms/)\n",
    "\n",
    "This tool has been designed to run in Jupyter Notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick use notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **issues relating to the script, a tutorial, or feedback** please contact Martin Job at martin.job@mdba.gov.au, Gabrielle Hunt at gabrielle.hunt@mdba.gov.au or Beau Byers at beau.byers@mdba.gov.au:\n",
    "1. Authenticate to GEE. Right-click on the link to open in a new tab, sign in, copy the code, paste it into the box and press 'enter' only.\n",
    "2. Press shift + enter on following cells until IHT Dashboard appears. Use the dashboard to input your selections. Start by selecting the Jupyter environment you are deploying the tool in, then a date range of interest, then defining the flow band of interest. You then have three options (select one) for defining the extents of your location of interest. Extents can be defined by either uploading a shapefile, typing in the coordinates manually, or using the coordinates of the gauge you selected in the previous step. You can then type in a gauge number and select if you want to include landsat 7 passes with the SLC failure (leading to stripes in these images)\n",
    "3. Press shift + enter until you get to 'PART 2'. Here you can toggle the satellite passes you wish to analyse and export based on their position on the hydrograph.\n",
    "5. Open your google cloud storage and download the Geotiff files for import into your preferred GIS software.\n",
    "6. OPTIONAL: download any of the plots of interest.\n",
    "7. OPTIONAL: Download the csv, containing the date of the satellite flyover, gauge reading, and whether you considered it a pass or fail.\n",
    "8. Once you have finished, restart the kernal to remove the variables and rerun the cells with your next parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load the packages and set up Earth Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the IHT foor the first time you may need to run the following cells to establish the environment. Uncomment the required cells.\n",
    "\n",
    "If running in Colab run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install jupyterlab ipywidgets geopandas ipyleaflet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the MDBA gauge getter:\n",
    "\n",
    "!git clone https://github.com/MDBAuth/MDBA_Gauge_Getter.git\n",
    "!cd MDBA_Gauge_Getter; python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1620201293658
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import ee\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import folium\n",
    "\n",
    "from MDBA_Gauge_Getter.mdba_gauge_getter import gauge_getter as gg\n",
    "\n",
    "# Local modules for IHT:\n",
    "import iht\n",
    "import iht_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gather": {
     "logged": 1615943274349
    }
   },
   "source": [
    "### 1.2 Authenticate and Initialise Google Earth Engine\n",
    "You may need to open the link in a new tab. Sign into you Google Earth Engine account and copy the code into the box. Then press `enter` (not `shift + enter`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1620201330864
    }
   },
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Set your parameters\n",
    "\n",
    "Run this cell and a dashboard will appear for you to interact with.\n",
    "\n",
    "1. Deployment environment (i.e. where is Jupyter running?)\n",
    "2. Start Date = Landsat imagery available from Oct 1987, Sentinel from Jul 2015\n",
    "3. Minimum flow = a value below 100 ML/day may result in the tool crashing due to too many images to process\n",
    "   Maximum flow = any value can be used\n",
    "4. Buffer (default 0.2) = buffer applied to selected area\n",
    "5. One of the options must be selected.\n",
    "   If the shapefile option is selected, all shapefile files must be loaded into the 'shapefile_inputs' folder within the IHT directory for the tool to access. WGS84 shapefile errors have been encountered, may require reprojection to GDA1994.\n",
    "6. Gauge number = can be found through the BoM (http://www.bom.gov.au/waterdata/) or by using the optional gauge map below the dashboard\n",
    "7. SLC failure = a sensor failure in Landsat 7 resulted in limited data collection after 21 May 2003, images may be useful for limited applications and are generally excluded\n",
    "8. Cloud threshold (default 5) = percentage of clouds in the image that the user belives is acceptable for your use, 0 would mean that only images with 0% cloud presence will be used, 100 would mean that images with up to 100% cloud cover will be used.\n",
    "9. Export variables = the users preference for different water indexes or RGB imagery which is exported in the final processes of the IHT.\n",
    "   Threshold for summary images (default 0.1) = MNDWI threshold for water detection, can be adjusted from -1 to 1, where all pixels above the threshold will be classified as water for calculation of % inundation\n",
    "   \n",
    "After selecting your variables, run the next cell to load them from the dashboard into the notebook.\n",
    "\n",
    "The final cell will allow you to check your area of interest to confirm that the spatial extent selected correctly matches with the users requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load the dashboard and save them to the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1620201331137
    }
   },
   "outputs": [],
   "source": [
    "iht.iht_dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have finished making your selections, run the below cell to commit them to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get IHT variables\n",
    "iht_values = iht.IhtValues()\n",
    "if not iht_values.valid:\n",
    "    for i in iht_values.errors:\n",
    "        print(i)\n",
    "    raise Exception(\"IHT input form errors exist. Please correct the above errors.\")\n",
    "\n",
    "flow_band = {\n",
    "    'min flow': iht_values.min_flow, \n",
    "    'max flow': iht_values.max_flow\n",
    "}\n",
    "\n",
    "# Pull gauge data then clean the gauge data into workable format:\n",
    "gauge_data = gg.gauge_pull([iht_values.gauge_num.replace(' ', '')],\n",
    "                                          iht_values.start_date, \n",
    "                                          iht_values.end_date)\n",
    "\n",
    "# Define an area of interest from the IHT results\n",
    "lat_low, lat_high, lon_low, lon_high = iht.get_coords()\n",
    "\n",
    "aoi = ee.Geometry.Polygon([[\n",
    "                            [lon_low, lat_low],\n",
    "                            [lon_low, lat_high],\n",
    "                            [lon_high, lat_high],\n",
    "                            [lon_high, lat_low]\n",
    "                          ]], None, False)\n",
    "# Get user request:\n",
    "define_gauge = iht_values.check_gauge\n",
    "define_coords = iht_values.check_own\n",
    "define_shapefile = iht_values.check_shapefile\n",
    "\n",
    "shapefile_name = iht_values.shapefile_loc\n",
    "\n",
    "# Mount Google Drive\n",
    "if iht_values.deploy_environment == 'Google colab':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('drive/MyDrive/IHT')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Gauge number map\n",
    "\n",
    "If you require assistance to find a suitable gauge number, run the optional cell below which will load an interactive map with gauge numbers, if you do not require it then skip running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gauge locations\n",
    "data = pd.read_csv('gauge_data/bom_gauge_data.csv')\n",
    "\n",
    "# Create a map\n",
    "this_map = folium.Map(prefer_canvas=True)\n",
    "\n",
    "def plotDot(point):\n",
    "    '''input: series that contains a numeric named latitude and a numeric named longitude\n",
    "    this function creates a CircleMarker and adds it to your this_map'''\n",
    "    try:\n",
    "        folium.CircleMarker(location=[point.lat, point.lon],\n",
    "                            radius=2,\n",
    "                            weight=5,\n",
    "                            popup=str(point['gauge number'])\n",
    "                           ).add_to(this_map)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# Use df.apply(,axis=1) to \"iterate\" through every row in your dataframe\n",
    "data.apply(plotDot, axis = 1)\n",
    "\n",
    "# Set the zoom to the maximum possible\n",
    "this_map.fit_bounds(this_map.get_bounds())\n",
    "\n",
    "this_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Confirm your area of interest:\n",
    "The cell below will create a custom map, and a red square will display where your area of interest (aoi) is based on your selections and inputs to the IHT Dashboard. If the aoi does not display, the tool does not have a spatial extent and will not be able to process your exports. The map may take some time to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1620201729170
    }
   },
   "outputs": [],
   "source": [
    "# Add EE drawing method to folium.\n",
    "folium.Map.add_ee_layer = iht_functions.add_ee_layer\n",
    "\n",
    "# Create a folium map object.\n",
    "m = folium.Map(location=[-32, 145], zoom_start=5, height=500)\n",
    "vis_params = {'palette':['#B22222'], 'opacity': 0.3}\n",
    "m.add_ee_layer(ee.Image(1).clip(aoi), vis_params, 'aoi')\n",
    "\n",
    "# Add a layer control panel to the map.\n",
    "m.add_child(folium.LayerControl())\n",
    "\n",
    "print('Your area of interest is show in red, click the checkbox to turn it off.')\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Loading and processing satellite imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load GEE imagery\n",
    "\n",
    "To load imagery from GEE generally you will need to:\n",
    "- define an area of interest and pass to `filterBounds`\n",
    "- define a time period of interest and pass to `filterDate`\n",
    "- filter on metadata (commonly cloud cover)\n",
    "- select bands of interest\n",
    "\n",
    ">**Note**: All options for how to manipulate GEE objects can be found in Google Earth Engine's [User Guides](https://developers.google.com/earth-engine/apidocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change dates to consistent datetime type to allow for comparison:\n",
    "slcError = datetime.strptime('2003-05-01','%Y-%m-%d').date()\n",
    "todays_date_str = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "start_date = iht_values.start_date\n",
    "end_date = iht_values.end_date\n",
    "\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "if iht_values.slc_option == 'Exclude':\n",
    "    end_time_ls7 = min(end_date, slcError).strftime('%Y-%m-%d')\n",
    "else:\n",
    "    end_time_ls7 = end_date_str\n",
    "\n",
    "# Filter landsat and sentinel collections to get desired image\n",
    "ls8_imcol = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
    "              .filterBounds(aoi) \\\n",
    "              .filterDate('2013-04-01', todays_date_str) \\\n",
    "              .filter(ee.Filter.lt('CLOUD_COVER',iht_values.cloud_threshold)) \\\n",
    "              .map(iht_functions.maskQuality)\\\n",
    "              .map(iht_functions.bands8)\n",
    "\n",
    "ls7_imcol = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
    "              .filterBounds(aoi) \\\n",
    "              .filterDate('1999-01-01',end_time_ls7) \\\n",
    "              .filter(ee.Filter.lt('CLOUD_COVER',iht_values.cloud_threshold)) \\\n",
    "              .map(iht_functions.maskQuality) \\\n",
    "              .map(iht_functions.bands57)\n",
    "\n",
    "ls5_imcol = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
    "              .filterBounds(aoi) \\\n",
    "              .filterDate('1984-03-01','2012-06-01') \\\n",
    "              .filter(ee.Filter.lt('CLOUD_COVER',iht_values.cloud_threshold)) \\\n",
    "              .map(iht_functions.maskQuality) \\\n",
    "              .map(iht_functions.bands57)\n",
    "\n",
    "ls_imcol = ls8_imcol.merge(ls7_imcol.merge(ls5_imcol)) \\\n",
    "                    .filterDate(start_date_str, end_date_str) \\\n",
    "                    .map(iht_functions.clipEdges)\n",
    "\n",
    "s_imcol = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
    "            .filterBounds(aoi) \\\n",
    "            .filterDate(start_date_str, end_date_str) \\\n",
    "            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',iht_values.cloud_threshold)) \\\n",
    "            .map(iht_functions.maskS2clouds) \\\n",
    "            .map(iht_functions.bandsS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the satellite times\n",
    "ls_times = iht_functions.getTime(ls_imcol)\n",
    "s_times = iht_functions.getTime(s_imcol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Filter satellite imagery and merge with gauge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the gauge data\n",
    "clean_gauge_data = iht_functions.gauge_data_cleaner(gauge_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will print a summary of the valid satellite passes that are available based on your preferences, note that more than 400 passes may cause the tool to crash. If the number of satelllite passes exceeds 400, consider constraining your variables in the IHT Dashboard (narrow date range, minimum and maximum flow thresholds or cloud threshold), and run all cells from the IHT Dashboard down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many passes you are about to load. \n",
    "#Loading over 400 passes may cause the kernal to crash\n",
    "print('Landsat has ' + iht_functions.countPasses(ls_times) + ' valid passes.')\n",
    "print('Sentinel has ' + iht_functions.countPasses(s_times) + ' valid passes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge satellite data with gauge data\n",
    "ls_count, ls_merged_data = iht_functions.merge_satellite_with_gauge(ls_times, clean_gauge_data, flow_band)  \n",
    "s_count, s_merged_data = iht_functions.merge_satellite_with_gauge(s_times, clean_gauge_data, flow_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a pandas dataframe    \n",
    "ls_all_merged_data = iht_functions.convert_to_pandas(ls_merged_data, ls_times)\n",
    "s_all_merged_data = iht_functions.convert_to_pandas(s_merged_data, s_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Graph all avaliable imagery\n",
    "This cell will create an interactive graph which will show you the Landsat and Sentinel images that are available based on your variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate graph showing the satellite passes relative to where they occur on the hydrograph\n",
    "fig_all = iht_functions.graph_all(flow_band, clean_gauge_data, ls_all_merged_data, s_all_merged_data)\n",
    "fig_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Separate passes into rising and falling categories based on gauge data\n",
    "\n",
    "This box will check whether the gauge-reading 21 days (`days_ahead`) after the satellite pass was higher or lower than the day of the satellite pass. The multiplier represents by how much more the water should be lower or higher to be considered a significant change. This (`multiplier`) has been defined as 1 for simplicity. It puts the pass either into the rising or falling list accordingly. It runs a loop to do this for every single pass. The output will tell you how many passes you got in each list and show you how the passes were catagorised on a hydrogaph. A manual reclassification is available later in the IHT to rectify any misclassifications.\n",
    "\n",
    "> **Note:** Check the graph in the output to see how well the data was separated. Consider changing `days_ahead` or `multiplier` in the code block below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Seperate passes into rising and falling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use custom functions to seperate into rising and falling\n",
    "\n",
    "multiplier = 1 # how much more the flow rate has to rise by to be considered a significant rise\n",
    "days_ahead = 21 # how many days in advance the algorithm checks for a rise or fall\n",
    "\n",
    "ls_rising, ls_falling = iht_functions.rising_falling_main(multiplier, days_ahead, clean_gauge_data, ls_all_merged_data)\n",
    "s_rising, s_falling = iht_functions.rising_falling_main(multiplier, days_ahead, clean_gauge_data, s_all_merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Graph the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_rising_falling = iht_functions.graph_rising_falling(flow_band, clean_gauge_data, ls_rising, ls_falling, s_rising, s_falling)\n",
    "graph_rising_falling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 5 - Decide which passes to include in the output\n",
    "\n",
    "The program has split the satellite passes into the rising and falling limb and allocated them to a 'pass' and 'fail' category respectively. Only the satellite passes in the 'pass' category will be analysed. View the graph below, and click on the satellite passes you would like to reclassify, and the program will reclassify them for you (depending on your deployment environment this feature may not be available to you; if this is the case, you will be able to reclassify using a dropdown list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Determine what passes will be accepted or rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_rising_clean = iht_functions.rising_falling_cleaner(ls_rising, 'landsat', 'accept')\n",
    "ls_falling_clean = iht_functions.rising_falling_cleaner(ls_falling, 'landsat', 'reject')\n",
    "s_rising_clean = iht_functions.rising_falling_cleaner(s_rising, 'sentinel', 'accept')\n",
    "s_falling_clean = iht_functions.rising_falling_cleaner(s_falling, 'sentinel', 'reject')\n",
    "    \n",
    "master_df = pd.concat([ls_rising_clean, ls_falling_clean, s_rising_clean, s_falling_clean])\n",
    "\n",
    "# Concatenate the landsats to the one dataframe, handle case where a dataframe could be empty:\n",
    "if ls_rising_clean is not None and ls_falling_clean is not None:\n",
    "    ls_only = pd.concat([ls_rising_clean, ls_falling_clean])\n",
    "elif ls_rising_clean is not None:\n",
    "    ls_only = ls_rising_clean.copy(deep=True)\n",
    "elif ls_falling_clean is not None:\n",
    "    ls_only = ls_falling_clean.copy(deep=True)\n",
    "    \n",
    "# Concatenate the landsats to the one dataframe, handle case where a dataframe could be empty:\n",
    "if s_rising_clean is not None and s_falling_clean is not None:\n",
    "    s_only = pd.concat([s_rising_clean, s_falling_clean])\n",
    "elif s_rising_clean is not None:\n",
    "    s_only = s_rising_clean.copy(deep=True)\n",
    "elif s_falling_clean is not None:\n",
    "    s_only = s_falling_clean.copy(deep=True)\n",
    "\n",
    "master_df_reindex = master_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Alternatively to accept all passes:\n",
    "# master_df_reindex = master_df_reindex.replace('sentinel reject','sentinel accept')\n",
    "# master_df_reindex = master_df_reindex.replace('landsat reject','landsat accept')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Graph accepted and rejected passes\n",
    "> **NOTE:** CLICK THE SATELLITE POINTS ON THE GRAPH TO CHANGE CATEGORY BETWEEN PASS AND FAIL AND VICE VERSA\n",
    "\n",
    "If running in Google Colab or AZML the graph will not be interactive. Use the date dropdown and redraw the graph to display changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_colab_or_AZML = iht_values.deploy_environment == 'Google colab' or iht_values.deploy_environment == 'AZML'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if google_colab_or_AZML:\n",
    "    fig = iht_functions.addAcceptRejectGraph(s_only, ls_only, master_df_reindex,clean_gauge_data,flow_band)\n",
    "    fig.show()\n",
    "else:\n",
    "    display(iht_functions.addAcceptRejectGraph(s_only, ls_only, master_df_reindex,clean_gauge_data,flow_band))\n",
    "    #TODO why is this not displaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if google_colab_or_AZML:\n",
    "    print('Use Crtl to select mutliple dates to switch from \"accept\" to \"reject\" and vice versa')\n",
    "    df = master_df_reindex\n",
    "    datelist  = sorted(df['date'].to_list())\n",
    "    widget_selection = widgets.SelectMultiple(\n",
    "        options=datelist,\n",
    "        disabled=False\n",
    "    )\n",
    "    display(widget_selection)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if google_colab_or_AZML:\n",
    "    # Get list of dates from widget\n",
    "    select_list = list(widget_selection.value)\n",
    "\n",
    "    # Select rows based on dates\n",
    "    df[df['date'].isin(select_list)]\n",
    "\n",
    "    # Add change column\n",
    "    df['Change'] = df['date'].isin(select_list)\n",
    "\n",
    "    master_df_reindex = df.apply(iht_functions.switch, axis=1)\n",
    "\n",
    "    fig = iht_functions.addAcceptRejectGraph(s_only, ls_only, master_df_reindex,clean_gauge_data,flow_band)\n",
    "    fig.show()\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Export imagery to Google Cloud\n",
    "Images can also be exported to Drive or as an Asset (see [Exporting Data](https://developers.google.com/earth-engine/guides/exporting) user guide). For large amounts of data you can download these to your local machine using [gsutil](https://cloud.google.com/storage/docs/gsutil) in the Google Cloud SDK. For small amounts the can be manually downloaded directly from Google Could or Google Drive.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section you:\n",
    "- Calculate indices:\n",
    "        - NDWI    \n",
    "        - MNDWI\n",
    "        - Fisher\n",
    "- Export single date images to Google Cloud/Drive.\n",
    "- Export summary images for each satellite (Sentinel-2 or Landsat series) to Google Cloud/Drive. Summary images are percent of water observations over clear observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Add indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_imcol_bands = ls_imcol.map(iht_functions.addMNDWI).map(iht_functions.addFisher).map(iht_functions.addNDWI)\n",
    "s_imcol_bands = s_imcol.map(iht_functions.addMNDWI).map(iht_functions.addFisher).map(iht_functions.addNDWI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Save your pass/fail selections from the graph in Part 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only acceptable passes\n",
    "passes_only = master_df_reindex[master_df_reindex['sat_result'].str.contains('accept')]  \n",
    "\n",
    "# Drop any duplicate dates - this won't affect the imagery but should be considered when looking at the gauge data\n",
    "passes_only = pd.DataFrame(passes_only,columns=['date','Value','sat_result'])\n",
    "passes_only = passes_only.drop_duplicates('date')\n",
    "\n",
    "# Keep only dates of interest\n",
    "dates_of_interest = passes_only['date'].values\n",
    "\n",
    "# Create array to decide on whether imagery is accepted or rejected\n",
    "sat_source = passes_only['sat_result'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Format file names for outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get description to make filenames more useful\n",
    "\n",
    "# If you have used the extents of the gauge, the gauge name will be used in the file name\n",
    "if define_gauge:\n",
    "    description = iht_values.gauge_num.replace(' ', '')\n",
    "# If you have defined your own coordinates, the gauge, lat, and lon will be used in the file name\n",
    "elif define_coords:\n",
    "    # TODO check this works, should have the lats and lons entered in the dashboard\n",
    "    description = f'{gauge}_lat{iht.input_lat.value}_lon{iht.input_lon.value}'\n",
    "# If you have uploaded a shapefile, the gauge number and shapefile name will be used in the file name\n",
    "elif define_shapefile:\n",
    "    file_ext = shapefile_name.split('/')[-1]\n",
    "    file_only = file_ext.split('.')[0]\n",
    "    description = f'{gauge}_{str(file_only)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Run the export script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_description = iht_values.band_option\n",
    "output_results = iht_values.export_images\n",
    "\n",
    "if band_description[0] == 'RGB':\n",
    "    export_bands = ['red','green','blue']\n",
    "elif band_description[0] == 'False_colour':\n",
    "    export_bands = ['swir2','nir','red']\n",
    "else:\n",
    "    export_bands = band_description\n",
    "\n",
    "# Run the export\n",
    "for i, day in enumerate(dates_of_interest):\n",
    "    \n",
    "    date_string = str(passes_only['date'].iloc[i].date())\n",
    "    \n",
    "    if sat_source[i] == 'landsat accept':\n",
    "        date_object = ee.Date.parse('YYYY-MM-dd', date_string)\n",
    "        end_date = date_object.advance(1,'day')\n",
    "        ls_im = ls_imcol_bands.filterDate(date_object,end_date).max() # when we do max the si dissapears\n",
    "        \n",
    "        for band in export_bands:\n",
    "            image = ls_im.select(export_bands)\n",
    "            task = ee.batch.Export.image.toCloudStorage(image=image, # an ee.Image object.\n",
    "                                                        description=(f'IHT_{description}_landsat_'\n",
    "                                                                     '{date_string}_{band_description[0]}'),\n",
    "                                                        bucket = 'mdba_gee_bucket',   \n",
    "                                                        region=aoi, # an ee.Geometry object.\n",
    "                                                        scale=30,\n",
    "                                                        crs='EPSG:4326',\n",
    "                                                        fileFormat='GeoTIFF')\n",
    "            if output_results == True:\n",
    "                task.start()\n",
    "                print('Exporting',task.status().get('description'))\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    elif sat_source[i] == 'sentinel accept':\n",
    "        date_object = ee.Date.parse('YYYY-MM-dd', date_string)\n",
    "        end_date = date_object.advance(1,'day')\n",
    "        s_im = s_imcol_bands.filterDate(date_object,end_date).max() # when we do max the si dissapears\n",
    "        \n",
    "        for band in export_bands:\n",
    "            image = s_im.select(export_bands)\n",
    "            task = ee.batch.Export.image.toCloudStorage(image=image,  # an ee.Image object.\n",
    "                                                        description=(f'IHT_{description}_sentinel_'\n",
    "                                                                     f'{date_string}_{band_description[0]}'),\n",
    "                                                        bucket = 'mdba_gee_bucket',   \n",
    "                                                        region=aoi, # an ee.Geometry object.\n",
    "                                                        scale=10,\n",
    "                                                        crs='EPSG:4326',\n",
    "                                                        fileFormat='GeoTIFF')\n",
    "            if output_results == True:\n",
    "                task.start()\n",
    "                print('Exporting',task.status().get('description'))\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check task status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Kill all tasks in emergency\n",
    "# for task in ee.batch.Task.list():\n",
    "#     task.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Exporting summary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Calculating summary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = [iht_values.summary_band_option]\n",
    "water_threshold = iht_values.water_threshold\n",
    "\n",
    "ls_water_list = []\n",
    "ls_clear_list = []\n",
    "s_water_list = []\n",
    "s_clear_list = []\n",
    "\n",
    "for i, day in enumerate(dates_of_interest):\n",
    "        \n",
    "    date_string = str(passes_only['date'].iloc[i].date())\n",
    "    \n",
    "    if sat_source[i] == 'landsat accept':\n",
    "        date_object = ee.Date.parse('YYYY-MM-dd', date_string)\n",
    "        end_date = date_object.advance(1,'day')\n",
    "        ls_im = ls_imcol_bands.filterDate(date_object,end_date).max() # when we do max the si dissapears\n",
    "        ls_water = ls_im.select(band).gt(water_threshold)\n",
    "        ls_water_list.append(ls_water)\n",
    "        ls_clear = ls_im.select('red').gt(0)\n",
    "        ls_clear_list.append(ls_clear)\n",
    "    \n",
    "    elif sat_source[i] == 'sentinel accept':\n",
    "        date_object = ee.Date.parse('YYYY-MM-dd', date_string)\n",
    "        end_date = date_object.advance(1,'day')\n",
    "        s_im = s_imcol_bands.filterDate(date_object,end_date).max() # when we do max the si dissapears\n",
    "        s_water = s_im.select(band).gt(water_threshold)\n",
    "        s_water_list.append(s_water)\n",
    "        s_clear = s_im.select('red').gt(0)\n",
    "        s_clear_list.append(s_clear)\n",
    "\n",
    "# Calculate sum of observations of water\n",
    "ls_sum_water = ee.ImageCollection(ls_water_list).reduce(ee.Reducer.sum()).toInt()\n",
    "s_sum_water = ee.ImageCollection(s_water_list).reduce(ee.Reducer.sum()).toInt()\n",
    "\n",
    "# Calculate sum of clear observations\n",
    "ls_sum_clear = ee.ImageCollection(ls_clear_list).reduce(ee.Reducer.sum()).toInt()\n",
    "s_sum_clear = ee.ImageCollection(s_clear_list).reduce(ee.Reducer.sum()).toInt()\n",
    "\n",
    "# Calculate percent water observations of total possible observations\n",
    "ls_percent = ls_sum_water.divide(ls_sum_clear).multiply(100)\n",
    "s_percent = s_sum_water.divide(s_sum_clear).multiply(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Display summary images on folium map\n",
    "- Sum_water: showing the maximum extent of water in the date range\n",
    "- Sum_clear: Showing if there were any pixels covered in cloud for the whole date range\n",
    "- Percent: Showing the percent of inundation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folium map object.\n",
    "my_map = folium.Map(location=[-32, 145], zoom_start=5, height=500)\n",
    "\n",
    "# Set visualization parameters.\n",
    "vis_params = {'min': 0,'max': 1}\n",
    "vis_params_percent = {'min': 0,'max': 100, 'palette':['white','0061A1']}\n",
    "\n",
    "# Add the elevation model to the map object.\n",
    "try:\n",
    "    my_map.add_ee_layer(ls_sum_water.clip(aoi), vis_params, 'ls_sum_water')\n",
    "    my_map.add_ee_layer(ls_sum_clear.clip(aoi), vis_params, 'ls_sum_clear')\n",
    "    my_map.add_ee_layer(ls_percent.clip(aoi).selfMask(), vis_params_percent, 'ls_percent')\n",
    "except:\n",
    "    print('No Landsat layers to add to map')\n",
    "\n",
    "try:\n",
    "    my_map.add_ee_layer(s_sum_water.clip(aoi), vis_params, 's_sum_water')\n",
    "    my_map.add_ee_layer(s_sum_clear.clip(aoi), vis_params, 's_sum_clear')\n",
    "    my_map.add_ee_layer(s_percent.clip(aoi).selfMask(), vis_params_percent, 's_percent')\n",
    "except:\n",
    "    print('No Sentinel layers to add to map')\n",
    "    \n",
    "my_map.add_ee_layer(ee.Image(1).clip(aoi), {'palette':['red']}, 'aoi')\n",
    "\n",
    "# Add a layer control panel to the map.\n",
    "my_map.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "print('Hover over the layers and select the layer of interest to view.')\n",
    "print('Your area of interest is show in red, click the checkbox to turn it off.')\n",
    "display(my_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Export the summary images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_summary = iht_values.export_summary_images\n",
    "\n",
    "# Run the export\n",
    "task = ee.batch.Export.image.toCloudStorage(image=s_percent,  # an ee.Image object.\n",
    "                                            description=f'IHT_{description}_sentinel_percent_{band[0]}',\n",
    "                                            bucket='mdba_gee_bucket',\n",
    "                                            region=aoi,  # an ee.Geometry object.\n",
    "                                            scale=10,\n",
    "                                            crs='EPSG:4326',\n",
    "                                            fileFormat='GeoTIFF')\n",
    "if run_summary:\n",
    "    task.start()\n",
    "\n",
    "task = ee.batch.Export.image.toCloudStorage(image=ls_percent,  # an ee.Image object.\n",
    "                                            description='IHT_{description}_landsat_percent_{band[0]}',\n",
    "                                            bucket = 'mdba_gee_bucket',\n",
    "                                            region=aoi,  # an ee.Geometry object.\n",
    "                                            scale=30,\n",
    "                                            crs='EPSG:4326',\n",
    "                                            fileFormat='GeoTIFF')\n",
    "if run_summary:\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check on task status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting hydrograph 1: all satellite flyovers on the gauge data:\n",
    "py.plot(fig_all,filename='hydrograph_outputs/'+description+'_'+datetime.today().strftime('%Y%m%d')+'_all_passes_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting hydrograph 2: satellite passes divided into rising and falling cats with gauge data\n",
    "py.plot(graph_rising_falling,filename='hydrograph_outputs/'+description+'_'+datetime.today().strftime('%Y%m%d')+'_rising_falling_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting hydrograph 3: satellite passes divided into the \n",
    "# final accept/reject categories with gauge data:\n",
    "py.plot(AcceptRejectGraph,filename='hydrograph_outputs/'+description+'_'+datetime.today().strftime('%Y%m%d')+'_accept_reject_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting the dataframe to the csv\n",
    "master_df_reindex.to_csv(\"csv_outputs/\"+description+'_'+datetime.today().strftime('%Y%m%d')+'_all_fly_overs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHT complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "IHT",
   "language": "python",
   "name": "iht"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
