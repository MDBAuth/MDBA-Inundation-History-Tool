{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inundation History Tool v2\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `DEA Sandbox` environment\n",
    "* **Products used:** \n",
    "['ga_ls5t_ard_3'](https://explorer.sandbox.dea.ga.gov.au/ga_ls5t_ard_3),\n",
    "['ga_ls7e_ard_3'](https://explorer.sandbox.dea.ga.gov.au/ga_ls7e_ard_3),\n",
    "['ga_ls8c_ard_3'](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3),\n",
    "['s2a_ard_granule'](https://explorer.sandbox.dea.ga.gov.au/ga_ls7e_ard_3),\n",
    "['s2b_ard_granule'](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3),\n",
    "[BoM Water Data Online](http://www.bom.gov.au/waterdata/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool is used for associating river flow rates with Landsat and Sentinel satellite passes. It filters satellite passes within defined flow bands of interest, removes poor quality satellite data, and also applies a filter to those images on the rising/falling limb. The images are then analysed using the Fisher index, MNDWI, and a False colour (Burnsie Index) for water identification in the landscape. \n",
    "\n",
    "The tool outputs the images as NetCDF files for use in GIS software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick use notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **issues relating to the script, a tutorial, or feedback** please contact Martin Job at martin.job@mdba.gov.au or David Weldrake at david.weldrake@mdba.gov.au\n",
    "1. Press shift + enter on cells until a map appears, select the gauge of interest from the map. Make sure to click \"done\" after you have selected your gauge.\n",
    "2. Use the dashboard under the map to input your selections. Start by defining the flow band of interest. You then have three options for defining the extents of your location of interest. Extents can be defined by uploading a shapefile, typing in the coordinates manually, or using the coordinates of the gauge you selected in the previous step. \n",
    "3. Press shift + enter until you get to 'PART 2'. Here you can toggle the satellite passes you wish to analyse and export based on their position on the hydrograph.\n",
    "5. Download the NetCDF files for import into your preferred GIS software, and inspect the thumbail images for each satellite flyover.\n",
    "6. OPTIONAL: download any of the plots of interest.\n",
    "7. OPTIONAL: Download the csv, containing the date of the flyover, gauge reading, and whether you considered it a pass or fail.\n",
    "8. Go back to the gauge selecting map at the top of the page, re-run this cell, and select a new gauge, repeat the process to get this new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Load key Python packages and supporting functions for the analysis. This notebook relies on modules called `dea_bom` and `dea_datahandling`, which are located in the `Scripts` directory, and the `IHT` module located in the `iht_modules` directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2 changes:\n",
    "\n",
    "- Integrate Sentinel 2\n",
    "- Additional band combinations (the false colour 'Burnsie index')\n",
    "- Implementing widgets for user inputs\n",
    "- Automatic uploading to the MDBA arcgis portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import datacube\n",
    "from datacube import Datacube\n",
    "from datacube.utils import geometry \n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.drivers.netcdf import write_dataset_to_netcdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='datacube')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append(os.path.abspath('/home/jovyan/Scripts'))\n",
    "import dea_bom\n",
    "from dea_datahandling import load_ard\n",
    "from iht_modules import iht\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.dates\n",
    "import plotly.offline as py\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing and loading the gauge information from BOM's Water Data Online "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache\n",
      "4303 stations loaded; e.g.:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[namespace(name='15 MILE @ GRETA STH',\n",
       "           url='http://bom.gov.au/waterdata/services/stations/403213',\n",
       "           pos=(-36.61945775, 146.24407214)),\n",
       " namespace(name='15 MILE @ WANGARATTA',\n",
       "           url='http://bom.gov.au/waterdata/services/stations/403239',\n",
       "           pos=(-36.36666667, 146.2833333)),\n",
       " namespace(name='16 Mile Waterhole',\n",
       "           url='http://bom.gov.au/waterdata/services/stations/913010A',\n",
       "           pos=(-18.876921, 139.360487)),\n",
       " namespace(name='163 Clifton Rd',\n",
       "           url='http://bom.gov.au/waterdata/services/stations/6131318',\n",
       "           pos=(-32.97808, 115.90111)),\n",
       " namespace(name='18 Mile Swamp HorseX',\n",
       "           url='http://bom.gov.au/waterdata/services/stations/144005A',\n",
       "           pos=(-27.49561971, 153.50836409))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_pkl = Path('/home/jovyan/Supplementary_data/Inundation_mapping/stations.pkl')\n",
    "\n",
    "# If cache exists, get station data from cache\n",
    "if stations_pkl.exists():\n",
    "    print('Loading from cache')\n",
    "    stations = pickle.load(open(str(stations_pkl), 'rb'))\n",
    "else:\n",
    "    print('Fetching from BoM')\n",
    "    stations = dea_bom.get_stations()\n",
    "    pickle.dump(stations, open(str(stations_pkl), 'wb'))\n",
    "\n",
    "# Filter list to stations with available data\n",
    "stations_with_data = pickle.load(open(str('/home/jovyan/Supplementary_data/Inundation_mapping/stations_with_data.pkl'), 'rb'))\n",
    "stations = [i for i in stations if i.name in stations_with_data]\n",
    "\n",
    "# Preview the first five stations loaded\n",
    "print(f'{len(stations)} stations loaded; e.g.:')\n",
    "stations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_data, station = dea_bom.ui_select_station(stations,\n",
    "                                                zoom=5,\n",
    "                                                center=(-34.72, 143.17));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input user preferences for lat, lon, satellite buffer, and flow thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iht.iht_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaxis_lower_parameter, yaxis_higher_parameter = iht.get_flow_bounds(iht.min_flow.value, \n",
    "                                                                    iht.max_flow.value)\n",
    "\n",
    "lat_low, lat_high, lon_low, lon_high = iht.get_coords(iht.check_gauge.value,\n",
    "                                                  iht.check_own.value,\n",
    "                                                  iht.input_lat.value,\n",
    "                                                  iht.input_lon.value,\n",
    "                                                  iht.check_shapefile.value, \n",
    "                                                  iht.shapefile_loc.value, \n",
    "                                                  iht.buffer.value,\n",
    "                                                  station.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Landsat and Sentinel passes for the location of interest\n",
    "\n",
    "The second cell in this block will take up to 5 minutes to run, as it is loading the satellite passes, applying a cloud filter and filtering out passes with poor coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_dc = datacube.Datacube(app='Loading Landsat IHT')\n",
    "\n",
    "todays_date = str(datetime.today().strftime('%Y-%m-%d')) \n",
    "\n",
    "landsat_query = {\n",
    "    'x': (lon_low, lon_high),\n",
    "    'y': (lat_low, lat_high),\n",
    "    'time': ('1988-01-01', todays_date),\n",
    "    'measurements': [\"nbart_red\"],\n",
    "    'output_crs': 'EPSG:3577',\n",
    "    'resolution': (-30, 30),\n",
    "    'group_by': 'solar_day'\n",
    "}\n",
    "\n",
    "# Load available data from all three Landsat satellites using the above query\n",
    "# Please note the two available options below. You can uncomment the min_gooddata and \n",
    "# change this value to reflect the minimum good quality pixels to include (0.6 = 60%)\n",
    "# Changing the ls7_slc_off variable to True will include ls7 passes with the slc failure\n",
    "landsat_ds = load_ard(dc=landsat_dc, \n",
    "              products=['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3'],\n",
    "              mask_pixel_quality=True,\n",
    "              min_gooddata=0.60, #Toggle number between 0 and 1 (default is 0.6)\n",
    "              ls7_slc_off=False, # Change to True to include Ls7 passes with slc failure\n",
    "              dask_chunks={}, \n",
    "              **landsat_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_dc = datacube.Datacube(app='Loading sentinel IHT')\n",
    "\n",
    "sentinel_query = {\n",
    "    'x': (lon_low, lon_high),\n",
    "    'y': (lat_low, lat_high),\n",
    "    'time': ('2015-06-23', todays_date),\n",
    "    'measurements': ['nbart_red'],\n",
    "    'output_crs': 'EPSG:3577',\n",
    "    'resolution': (-10, 10),\n",
    "    'group_by': 'solar_day'\n",
    "}\n",
    "\n",
    "# Load available data from both Sentinel 2 satellites\n",
    "sentinel_ds = load_ard(dc=sentinel_dc,\n",
    "              products=['s2a_ard_granule', 's2b_ard_granule'],\n",
    "              min_gooddata=0.10,\n",
    "              mask_pixel_quality=True,         \n",
    "              dask_chunks={},\n",
    "              **sentinel_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out passes for dates within the flow bands of interest and\n",
    " ### Merging the satellite passes with the gauge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauge_data_cleaner(input_data):\n",
    "    '''Ingests a pd.df of flow timeseries, \n",
    "    converts data types and measurements,\n",
    "    returns clean gauge data'''\n",
    "    gauge_df = input_data.copy(deep = True)\n",
    "    gauge_df[\"Value\"] = pd.to_numeric(gauge_df[\"Value\"], downcast=\"float\")\n",
    "    gauge_df['Value'] = gauge_df['Value']*86.4\n",
    "    gauge_df.index = gauge_df.index.normalize()\n",
    "    \n",
    "    return gauge_df\n",
    "\n",
    "clean_gauge_data = gauge_data_cleaner(gauge_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_satellite_with_gauge(sat_input, gauge_input):\n",
    "    '''Ingests gauge data and satellite data xr,\n",
    "    identifies where on the gauge data there are passes and works out how many fall within the\n",
    "    flow bands of interest,\n",
    "    returns the dates, how many there are, and the xarray of the merged data\n",
    "    '''\n",
    "    gauge_data_xr = gauge_input.to_xarray() \n",
    "    merged_data = gauge_data_xr.interp(Timestamp=sat_input.time)\n",
    "    specified_satellite_passes = merged_data.where(((merged_data.Value > yaxis_lower_parameter) &\\\n",
    "                                                    (merged_data.Value < yaxis_higher_parameter)), \n",
    "                                                   drop=True)\n",
    "    specified_satellite_passes = specified_satellite_passes.drop('Timestamp')\n",
    "    date_list = specified_satellite_passes.time.values\n",
    "    \n",
    "    how_many = specified_satellite_passes.time.shape[0]\n",
    "    \n",
    "    return date_list, how_many, merged_data\n",
    "\n",
    "ls_date_list, ls_count, ls_merged_data = merge_satellite_with_gauge(landsat_ds, clean_gauge_data)  \n",
    "s_date_list, s_count, s_merged_data = merge_satellite_with_gauge(sentinel_ds, clean_gauge_data)\n",
    "\n",
    "#Check how many passes you are about to load. \n",
    "#Loading over 400 passes may cause the kernal to crash\n",
    "print(\"You are about to load {} landsat passes\".format(ls_count))\n",
    "print(\"You are about to load {} sentinel passes\".format(s_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_passes(input_sat_passes, input_date_list):\n",
    "    '''Ingests satellite data dask array and the required dates,\n",
    "    computes the dask array for these dates only'''\n",
    "    \n",
    "    computed = input_sat_passes.sel(time=input_date_list).compute()\n",
    "    \n",
    "    return computed\n",
    "    \n",
    "ls_specified_passes = compute_passes(landsat_ds, ls_date_list)\n",
    "s_specified_passes = compute_passes(sentinel_ds, s_date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pandas(input_merged_data, input_specified_passes):\n",
    "    ''' Converts to dataframe \n",
    "    returns the dataframe with the gauge reading at the time of the satellite pass '''\n",
    "    merged_data_pd = input_merged_data.to_dataframe()\n",
    "    \n",
    "    all_specified_passes_pd = input_specified_passes.time.to_dataframe()\n",
    "    all_specified_passes_pd = all_specified_passes_pd.rename(columns = {'time': 'date'})\n",
    "    \n",
    "    all_merged_data = pd.merge(all_specified_passes_pd, merged_data_pd, left_on= 'time', \n",
    "                                right_index=True, how='inner')\n",
    "    all_merged_data = all_merged_data.drop(columns='date')\n",
    "    all_merged_data = all_merged_data.drop(columns='Timestamp')\n",
    "    all_merged_data.index = all_merged_data.index.normalize()\n",
    "    all_merged_data.index.name = 'date'\n",
    "    \n",
    "    return all_merged_data\n",
    "    \n",
    "ls_all_merged_data = convert_to_pandas(ls_merged_data, ls_specified_passes)\n",
    "s_all_merged_data = convert_to_pandas(s_merged_data, s_specified_passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_flow_bands_to_gauge_data(input_gauge_data):\n",
    "    ''' Adds the flow bands of interest to the gauge dataframe for graphing purposes '''\n",
    "\n",
    "    graph_gauge_df = input_gauge_data.copy(deep=True)\n",
    "    \n",
    "    graph_gauge_df['y_lower'] = yaxis_lower_parameter\n",
    "    graph_gauge_df['y_higher'] = yaxis_higher_parameter\n",
    "    \n",
    "    return graph_gauge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_all(input_gauge_data, input_ls, input_s):\n",
    "    ''' Function to generate a graph showing the satellite passes relative to where they occur\n",
    "    on the hydrograph '''\n",
    "    \n",
    "    # Set up the dataframe:\n",
    "    graph_gauge_df = add_flow_bands_to_gauge_data(input_gauge_data)\n",
    "    \n",
    "    fig_all = go.Figure()\n",
    "    \n",
    "    # Add gauge data:\n",
    "    fig_all.add_trace(go.Scatter(name = 'Gauge data',\n",
    "                                x = graph_gauge_df.index,\n",
    "                                y = graph_gauge_df['Value'],\n",
    "                                mode = 'lines',\n",
    "                                line = dict(color = 'royalblue', width = 1),\n",
    "                                hovertemplate = 'flow: %{y:.2f}<extra></extra>' +\n",
    "                                 '<br><b>Date</b>: %{x}<br>'\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    # Add landsat:\n",
    "    fig_all.add_trace(go.Scatter(name = 'Landsat pass',\n",
    "                                x = input_ls.index,\n",
    "                                y = input_ls['Value'],\n",
    "                                mode = 'markers',\n",
    "                                line = dict(color = 'green', width = 2), \n",
    "                                hovertemplate = 'Landsat pass <extra></extra>' +\n",
    "                                '<br><b>Date</b>: %{x}<br>',\n",
    "                                marker_size = 9\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    # Add sentinel:\n",
    "    fig_all.add_trace(go.Scatter(name = 'Sentinel pass',\n",
    "                                x = input_s.index,\n",
    "                                y = input_s['Value'],\n",
    "                                mode = 'markers',\n",
    "                                line = dict(color = 'lightseagreen', width = 2), \n",
    "                                hovertemplate = 'Sentinel pass <extra></extra>' +\n",
    "                                 '<br><b>Date</b>: %{x}<br>',\n",
    "                                marker_symbol = 'cross',\n",
    "                                marker_size = 9\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    # Adding the lower flow bounds:\n",
    "    fig_all.add_trace(go.Scatter(name = 'lower flow bound',\n",
    "                                x = graph_gauge_df.index,\n",
    "                                y = graph_gauge_df['y_lower'],\n",
    "                                mode = 'lines',\n",
    "                                line = dict(color = 'black', width = 2)\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    # Adding the upper flow bounds:\n",
    "    fig_all.add_trace(go.Scatter(name = 'upper flow bound',\n",
    "                                x = graph_gauge_df.index,\n",
    "                                y = graph_gauge_df['y_higher'],\n",
    "                                mode = 'lines',\n",
    "                                line = dict(color = 'black', width = 2)\n",
    "                                )\n",
    "                     )\n",
    "\n",
    "    fig_all.update_layout(hovermode=\"closest\",\n",
    "                                     title= 'Landsat and Sentinel passes within the flow band of interest',\n",
    "                                     xaxis_title='Date',\n",
    "                                     yaxis_title='Flow at gauge (ML/Day)',\n",
    "                                     font=dict(family='Calibri', size=16, color='black'),\n",
    "                                     paper_bgcolor='white',\n",
    "                                     plot_bgcolor='white',\n",
    "                                     hoverlabel=dict(\n",
    "                                         bgcolor=\"white\",\n",
    "                                         font_size=16,\n",
    "                                         font_family=\"Rockwell\")) \n",
    "    \n",
    "    return fig_all\n",
    "\n",
    "fig_all = graph_all(clean_gauge_data, ls_all_merged_data, s_all_merged_data)\n",
    "fig_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now separate the gauge data into 2 lists: rising and falling. Check the graph in the output to see how well the data was separated\n",
    "\n",
    "This box will check whether the gauge-reading 21 (can change with user input) days after the satellite pass was higher or lower than the day of the satellite pass. The multiplier represents by how much more the water should be lower or higher to be considered a significant change. This has been defined as 1 for simplicity (can also change with user input). It puts the pass either into the rising or falling list accordingly. It runs a loop to do this for every single pass. The output will tell you how many passes you got in each list and show you how the passes were catagorised on a hydrogaph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rising_falling_main(multiplier, days_ahead, input_gauge_df, input_sat_passes):\n",
    "    ''' Split the satellite passes into either the rising or falling category '''\n",
    "\n",
    "    rising_list = list()\n",
    "    falling_list = list()\n",
    "    \n",
    "    for i, flow in enumerate(input_gauge_df['Value'][:len(input_gauge_df['Value'])-days_ahead]):\n",
    "        if flow < input_gauge_df['Value'][i + days_ahead] * multiplier:\n",
    "            rising_list.append(input_gauge_df.index[i])\n",
    "        else:\n",
    "            falling_list.append(input_gauge_df.index[i])\n",
    "    \n",
    "    rising_passes = list(set(rising_list) & set(list(input_sat_passes.index)))\n",
    "    falling_passes = list(set(falling_list) & set(list(input_sat_passes.index)))\n",
    "\n",
    "    rising_passes_df = df_constructor(rising_passes, input_sat_passes)\n",
    "    falling_passes_df = df_constructor(falling_passes, input_sat_passes)\n",
    "    \n",
    "    return rising_passes_df, falling_passes_df\n",
    "\n",
    "def df_constructor(input_list, sat_data_to_join):\n",
    "    ''' converts the list of either rising or falling passes into a dataframe '''\n",
    "    \n",
    "    df = pd.DataFrame(input_list, columns = ['date'])\n",
    "    df['date'] = pd.to_datetime(df['date'], format = '%Y-%m-%d')\n",
    "    df = df.set_index('date')\n",
    "    df = df.join(sat_data_to_join)\n",
    "    \n",
    "    return df\n",
    "\n",
    "multiplier = 1 # how much more the flow rate has to rise by to be considered a significant rise\n",
    "days_ahead = 21 # how many days in advance the algorithm checks for a rise or fall\n",
    "\n",
    "ls_rising, ls_falling = rising_falling_main(multiplier, days_ahead, clean_gauge_data, ls_all_merged_data)\n",
    "s_rising, s_falling = rising_falling_main(multiplier, days_ahead, clean_gauge_data, s_all_merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_rising_falling(input_gauge_data, input_rising_ls, input_falling_ls, input_rising_s, \n",
    "                         input_falling_s):\n",
    "    ''' Function to generate a graph showing the satellite passes relative to where they occur\n",
    "    on the hydrograph and their respective category (either rising or falling)'''    \n",
    "    \n",
    "    graph_gauge_df = add_flow_bands_to_gauge_data(input_gauge_data)\n",
    "    \n",
    "    fig_rising_falling = go.Figure()\n",
    "    \n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'Gauge data',\n",
    "                                           x = graph_gauge_df.index,\n",
    "                                           y = graph_gauge_df['Value'],\n",
    "                                           mode = 'lines',\n",
    "                                           line = dict(color = 'royalblue', width = 1),\n",
    "                                           hovertemplate = 'flow: %{y:.2f}<extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>'\n",
    "                                           )\n",
    "                                )\n",
    "    \n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'Rising Landsat pass',\n",
    "                                           x = input_rising_ls.index,\n",
    "                                           y = input_rising_ls['Value'],\n",
    "                                           mode = 'markers',\n",
    "                                           marker_symbol = 'triangle-up',\n",
    "                                           marker_size = 9,\n",
    "                                           line = dict(color = 'green', width = 2),\n",
    "                                           hovertemplate = 'Rising Landsat pass <extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>'\n",
    "                                           )\n",
    "                                ) \n",
    "    \n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'Falling Landsat pass',\n",
    "                                           x = input_falling_ls.index,\n",
    "                                           y = input_falling_ls['Value'],\n",
    "                                           mode = 'markers',\n",
    "                                           marker_symbol = 'triangle-down',\n",
    "                                           marker_size = 9,\n",
    "                                           line = dict(color = 'crimson', width = 2),\n",
    "                                           hovertemplate = 'Falling Landsat pass <extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>'\n",
    "                                           )\n",
    "                                ) \n",
    "    \n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'Rising Sentinel pass',\n",
    "                                           x = input_rising_s.index,\n",
    "                                           y = input_rising_s['Value'],\n",
    "                                           mode = 'markers',\n",
    "                                           marker_symbol = 'star-triangle-up',\n",
    "                                           marker_size = 9,\n",
    "                                           line = dict(color = 'lightseagreen', width = 2),\n",
    "                                           hovertemplate = 'Rising Sentinel pass <extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>'\n",
    "                                           )\n",
    "                                ) \n",
    "        \n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'Falling Sentinel pass',\n",
    "                                           x = input_falling_s.index,\n",
    "                                           y = input_falling_s['Value'],\n",
    "                                           mode = 'markers',\n",
    "                                           marker_symbol = 'star-triangle-down',\n",
    "                                           marker_size = 9,\n",
    "                                           line = dict(color = 'purple', width = 2),\n",
    "                                           hovertemplate = 'Falling Sentinel pass <extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>'\n",
    "                                           )\n",
    "                                ) \n",
    "    \n",
    "    # Adding the lower flow bounds:\n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'lower flow bound',\n",
    "                                x = graph_gauge_df.index,\n",
    "                                y = graph_gauge_df['y_lower'],\n",
    "                                mode = 'lines',\n",
    "                                line = dict(color = 'black', width = 2)\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    # Adding the upper flow bounds:\n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'upper flow bound',\n",
    "                                x = graph_gauge_df.index,\n",
    "                                y = graph_gauge_df['y_higher'],\n",
    "                                mode = 'lines',\n",
    "                                line = dict(color = 'black', width = 2)\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    fig_rising_falling.update_layout(hovermode=\"closest\",\n",
    "                                 title= 'Sentinel and Landsat broken into rising/falling categories',\n",
    "                                 xaxis_title='Date',\n",
    "                                 yaxis_title='Flow at gauge (ML/Day)',\n",
    "                                 font=dict(family='Calibri', size=16, color='black'),\n",
    "                                 paper_bgcolor='white',\n",
    "                                 plot_bgcolor='white',\n",
    "                                 hoverlabel=dict(\n",
    "                                     bgcolor=\"white\",\n",
    "                                     font_size=16,\n",
    "                                     font_family=\"Rockwell\")\n",
    "                                    ) \n",
    "    \n",
    "    return fig_rising_falling\n",
    "\n",
    "\n",
    "print(\"{} rising landsat passes\".format(len(ls_rising)))\n",
    "print(\"{} falling landsat passes\".format(len(ls_falling)))\n",
    "print(\"{} rising sentinel passes\".format(len(s_rising)))\n",
    "print(\"{} falling sentinel passes\".format(len(s_falling)))\n",
    "graph_rising_falling = graph_rising_falling(clean_gauge_data, ls_rising, ls_falling, s_rising, s_falling)\n",
    "graph_rising_falling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rising_falling_cleaner(input_df, sat_source, pass_or_fail):\n",
    "    ''' Ingests rising or falling dataframe,\n",
    "    drops the columns not required for the rest of the analysis,\n",
    "    adds column for the satellite and whether or not it will be rejected/passed'''\n",
    "    \n",
    "    df = input_df.copy(deep = True)\n",
    "    \n",
    "    df = df.drop(['spatial_ref_x', 'spatial_ref_y'], axis = 1)\n",
    "    df['sat_result'] = str(sat_source + ' ' + pass_or_fail)\n",
    "    \n",
    "    return df\n",
    "\n",
    "ls_rising_clean = rising_falling_cleaner(ls_rising, 'landsat', 'accept')\n",
    "ls_falling_clean = rising_falling_cleaner(ls_falling, 'landsat', 'reject')\n",
    "s_rising_clean = rising_falling_cleaner(s_rising, 'sentinel', 'accept')\n",
    "s_falling_clean = rising_falling_cleaner(s_falling, 'sentinel', 'reject')\n",
    "    \n",
    "master_df = pd.concat([ls_rising_clean, ls_falling_clean, s_rising_clean, s_falling_clean])\n",
    "ls_only = pd.concat([ls_rising_clean, ls_falling_clean])\n",
    "s_only = pd.concat([s_rising_clean, s_falling_clean])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - Outputting the maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual check of satellite passes you would like to analyse\n",
    "The program has split the satellite passes into the rising and falling limb and allocated them to a 'pass' and 'fail' category respectively. Only the satellite passes in the 'pass' category will be analysed. View the graph below, and click on the satellite passes you would like the reclassify, and the program will reclassify them for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_reindex = master_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_colour(x):\n",
    "    '''Function to allocate a colour to the \n",
    "    sat pass depending on how it is classified '''\n",
    "    if (x == 'landsat accept'):    \n",
    "        return 'green'\n",
    "    elif (x == 'landsat reject'):\n",
    "        return 'red'\n",
    "    elif (x == 'sentinel accept'):\n",
    "        return 'purple'\n",
    "    else:\n",
    "        return 'lightpink' \n",
    "\n",
    "graph_gauge_df = add_flow_bands_to_gauge_data(clean_gauge_data)\n",
    "\n",
    "# Adding landsat trace:\n",
    "trace_sats = go.Scatter(name = 'Satellite pass',\n",
    "                      x = master_df_reindex['date'],\n",
    "                      y = master_df_reindex['Value'],\n",
    "                      mode = 'markers',\n",
    "                      marker = dict(size=8,\n",
    "                                    color=list(map(set_colour, master_df_reindex['sat_result']))),\n",
    "                      showlegend = False\n",
    "                     )  \n",
    "\n",
    "# Adding the gauge data:\n",
    "trace_gauge = go.Scatter(name = 'Gauge data',\n",
    "                     x = graph_gauge_df.index,\n",
    "                     y = graph_gauge_df['Value'],\n",
    "                     mode = 'lines',\n",
    "                     line = dict(color = 'royalblue', width = 1),\n",
    "                     hovertemplate = 'flow: %{y:.2f}<extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>')\n",
    "\n",
    "# Adding the lower flow bounds:\n",
    "trace_lower = go.Scatter(name = 'lower flow bound',\n",
    "                     x = graph_gauge_df.index,\n",
    "                     y = graph_gauge_df['y_lower'],\n",
    "                     mode = 'lines',\n",
    "                     line = dict(color = 'black', width = 2)\n",
    "                    )\n",
    "\n",
    "# Adding the upper flow bounds:\n",
    "trace_upper = go.Scatter(name = 'upper flow bound',\n",
    "                     x = graph_gauge_df.index,\n",
    "                     y = graph_gauge_df['y_higher'],\n",
    "                     mode = 'lines',\n",
    "                     line = dict(color = 'black', width = 2)\n",
    "                    )\n",
    "# Adding for legend\n",
    "trace_pass_ls = go.Scatter(name = 'landsat accepted',\n",
    "                     x=[None], y=[None],\n",
    "                     mode = 'markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'green'),\n",
    "                     showlegend = True)\n",
    "\n",
    "# Adding for legend\n",
    "trace_fail_ls = go.Scatter(name = 'landsat rejected', \n",
    "                     x=[None], y=[None],\n",
    "                     mode= ' markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'red'),\n",
    "                     showlegend = True)\n",
    "\n",
    "trace_pass_s = go.Scatter(name = 'sentinel accepted',\n",
    "                     x=[None], y=[None],\n",
    "                     mode = 'markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'purple'),\n",
    "                     showlegend = True)\n",
    "\n",
    "# Adding for legend\n",
    "trace_fail_s = go.Scatter(name = 'sentinel rejected', \n",
    "                     x=[None], y=[None],\n",
    "                     mode= ' markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'lightpink'),\n",
    "                     showlegend = True)\n",
    "\n",
    "# Add the traces to the figure:\n",
    "passing_failing_graph = go.FigureWidget(data=[trace_sats, trace_gauge, \n",
    "                                              trace_lower, trace_upper, \n",
    "                                              trace_pass_ls, trace_fail_ls,\n",
    "                                              trace_pass_s, trace_fail_s])\n",
    "\n",
    "passing_failing_graph.update_layout(hovermode=\"closest\",\n",
    "                          title= 'Proposed satellite passes to use in the analysis',\n",
    "                          xaxis_title='Date',\n",
    "                          yaxis_title='Flow at gauge (ML/Day)',\n",
    "                          font=dict(family='Calibri', size=16, color='black'),\n",
    "                          paper_bgcolor='white',\n",
    "                          plot_bgcolor='white',\n",
    "                          hoverlabel=dict(\n",
    "                              bgcolor=\"white\",\n",
    "                              font_size=16,\n",
    "                              font_family=\"Rockwell\")) \n",
    "\n",
    "scatter = passing_failing_graph.data[0]\n",
    "\n",
    "def update_point(trace, points, selector):\n",
    "    ''' Reclassify the points based on user selection '''\n",
    "    \n",
    "    try:\n",
    "        date = points.xs[0]\n",
    "        row_name = master_df_reindex.loc[master_df_reindex['date'] == date]\n",
    "        \n",
    "        if date in ls_only.index and date in s_only.index:\n",
    "            if 'accept' in row_name['sat_result'].iloc[0]:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'sat_result'] = 'landsat reject'\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'sat_result'] = 'sentinel reject'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['sat_result']))\n",
    "                print('the landsat and sentinel pass on ', date, ' has been reclassified to be rejected')\n",
    "            else:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'sat_result'] = 'landsat accept'\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'sat_result'] = 'sentinel accept'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['sat_result']))\n",
    "                print('the landsat and sentinel pass on ', date, ' has been reclassified to be accepted')\n",
    "        \n",
    "        elif date in ls_only.index and date not in s_only.index:\n",
    "            if row_name['sat_result'].iloc[0] == 'landsat accept':\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'sat_result'] = 'landsat reject'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['sat_result']))\n",
    "                print('the landsat pass on ', date, ' has been reclassified to be rejected')\n",
    "            else:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'sat_result'] = 'landsat accept'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['sat_result']))\n",
    "                print('the landsat pass on ', date, ' has been reclassified to be accepted')\n",
    "                \n",
    "        elif date in s_only.index and date not in ls_only.index:\n",
    "            if row_name['sat_result'].iloc[0] == 'sentinel accept':\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'sat_result'] = 'sentinel reject'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['sat_result']))\n",
    "                print('the sentinel pass on ', date, ' has been reclassified to be rejected')\n",
    "            else:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'sat_result'] = 'sentinel accept'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['sat_result']))\n",
    "                print('the sentinel pass on ', date, ' has been reclassified to be accepted')\n",
    "                \n",
    "    except IndexError:\n",
    "        print('You missed the satellite pass! Try click again')   \n",
    "\n",
    "scatter.on_click(update_point)\n",
    "\n",
    "passing_failing_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get only acceptable passes:\n",
    "passes_only = master_df_reindex[master_df_reindex['sat_result'].str.contains('accept')]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_of_interest = passes_only['date'].values\n",
    "sat_source = passes_only['sat_result'].values\n",
    "\n",
    "for i, day in enumerate(dates_of_interest):\n",
    "    \n",
    "    print(i)   \n",
    "    date_string = str(passes_only['date'].iloc[i].date())\n",
    "    print(date_string)\n",
    "    \n",
    "    if sat_source[i] == 'landsat accept':\n",
    "\n",
    "        file_extension = '.nc'\n",
    "        file_name = 'netcdf_outputs/' + date_string + 'landsat' + file_extension\n",
    "        # Create a reusable query\n",
    "        landsat_data_query = {\n",
    "            'x': (lon_low, lon_high),\n",
    "            'y': (lat_low, lat_high),\n",
    "            'time': (date_string),\n",
    "            'measurements': ['nbart_red', 'nbart_green', 'nbart_blue', \n",
    "                             'nbart_nir', 'nbart_swir_1', 'nbart_swir_2'],\n",
    "            'output_crs': 'EPSG:3577',\n",
    "            'resolution': (-30, 30),\n",
    "            'group_by': 'solar_day'\n",
    "        }\n",
    "\n",
    "        # Load available data from all three Landsat satellites\n",
    "        ls_ds = load_ard(dc=landsat_dc, \n",
    "                      products=['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3'],\n",
    "                      mask_pixel_quality=True,\n",
    "                      min_gooddata=0.60,\n",
    "                      ls7_slc_off=False, ## comment this to keep the images with the SLC error\n",
    "                      **landsat_data_query)\n",
    "\n",
    "        # Shows an RGB thumbnail of each pass:\n",
    "        ls_ds[['nbart_red', 'nbart_green', 'nbart_blue']].isel(time=0).to_array().plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Making an NDWI layer and showing a thumbnail of the output\n",
    "        ds_ndwi = (ls_ds.nbart_nir - ls_ds.nbart_swir_1) /(ls_ds.nbart_nir + ls_ds.nbart_swir_1)\n",
    "        ls_ds[\"NDWI\"] = ds_ndwi\n",
    "        ls_ds['NDWI'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Making the fisher index layer and showing a thumbnail of the output\n",
    "        ds_fisher = 1.7204+(171*ls_ds.nbart_green)+(3*ls_ds.nbart_red)-(70*ls_ds.nbart_nir)-(45*ls_ds.nbart_swir_1)-(71*ls_ds.nbart_swir_2)\n",
    "        ls_ds['Fisher'] = ds_fisher  \n",
    "        ls_ds['Fisher'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        ds_burnsie = (ls_ds.nbart_swir_2 + ls_ds.nbart_nir + ls_ds.nbart_red)\n",
    "        ls_ds['Burnsie'] = ds_burnsie \n",
    "        ls_ds['Burnsie'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Write the layers to a NetCDF, ready for importing\n",
    "        try:\n",
    "            write_dataset_to_netcdf(ls_ds, file_name)\n",
    "        except RuntimeError:\n",
    "            print('***THIS FILE NAME ALREADY EXISTS, PLEASE SAVE YOUR NETCDF FILES TO ANOTHER DIRECTORY***')\n",
    "            break\n",
    "            \n",
    "    ########################################                \n",
    "    elif sat_source[i] == 'sentinel accept':\n",
    "        \n",
    "        file_extension = '.nc'\n",
    "        file_name = 'netcdf_outputs/' + date_string + 'sentinel' + file_extension\n",
    "        # Create a reusable query\n",
    "        sentinel_data_query = {\n",
    "            'x': (lon_low, lon_high),\n",
    "            'y': (lat_low, lat_high),\n",
    "            'time': (date_string),\n",
    "            'measurements': ['nbart_red', 'nbart_green', 'nbart_blue', \n",
    "                             'nbart_nir_1', 'nbart_swir_2', 'nbart_swir_3'],\n",
    "            'output_crs': 'EPSG:3577',\n",
    "            'resolution': (-10, 10),\n",
    "            'group_by': 'solar_day'\n",
    "        }\n",
    "\n",
    "        # Load available data from all three Landsat satellites\n",
    "        s_ds = load_ard(dc=sentinel_dc,\n",
    "                      products=['s2a_ard_granule', 's2b_ard_granule'],\n",
    "                      min_gooddata=0.10,\n",
    "                      mask_pixel_quality=True,         \n",
    "                      dask_chunks={},\n",
    "                      **sentinel_data_query)\n",
    "\n",
    "        # Shows an RGB thumbnail of each pass:\n",
    "        s_ds[['nbart_red', 'nbart_green', 'nbart_blue']].isel(time=0).to_array().plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Making an NDWI layer and showing a thumbnail of the output\n",
    "        ds_ndwi = (s_ds.nbart_nir_1 - s_ds.nbart_swir_2) /(s_ds.nbart_nir_1 + s_ds.nbart_swir_2)\n",
    "        s_ds[\"NDWI\"] = ds_ndwi\n",
    "        s_ds['NDWI'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Making the fisher index layer and showing a thumbnail of the output\n",
    "        ds_fisher = 1.7204+(171*s_ds.nbart_green)+(3*s_ds.nbart_red)-(70*s_ds.nbart_nir_1)-(45*s_ds.nbart_swir_2)-(71*s_ds.nbart_swir_3)\n",
    "        s_ds['Fisher'] = ds_fisher  \n",
    "        s_ds['Fisher'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        ds_burnsie = (s_ds.nbart_swir_2 + s_ds.nbart_nir_1 + s_ds.nbart_red)\n",
    "        s_ds['Burnsie'] = ds_burnsie \n",
    "        s_ds['Burnsie'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Write the layers to a NetCDF, ready for importing\n",
    "        try:\n",
    "            write_dataset_to_netcdf(s_ds, file_name)\n",
    "            \n",
    "        except RuntimeError:\n",
    "            print('***THIS FILE NAME ALREADY EXISTS, PLEASE SAVE YOUR NETCDF FILES TO ANOTHER DIRECTORY***')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting hydrograph 1: all satellite flyovers on the gauge data:\n",
    "py.plot(fig_all,filename='hydrograph_outputs/all_passes_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting hydrograph 2: satellite passes divided into rising and falling cats with gauge data\n",
    "py.plot(graph_rising_falling,filename='hydrograph_outputs/rising_falling_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting hydrograph 3: satellite passes divided into the \n",
    "# final pass/fail categories with gauge data:\n",
    "py.plot(passing_failing_graph, filename='hydrograph_outputs/pass_fail_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting the dataframe to the csv\n",
    "master_df_reindex.to_csv(\"csv_outputs/all_fly_overs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
