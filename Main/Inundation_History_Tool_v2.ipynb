{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inundation History Tool v2\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `DEA Sandbox` environment\n",
    "* **Products used:** \n",
    "['ga_ls5t_ard_3'](https://explorer.sandbox.dea.ga.gov.au/ga_ls5t_ard_3),\n",
    "['ga_ls7e_ard_3'](https://explorer.sandbox.dea.ga.gov.au/ga_ls7e_ard_3),\n",
    "['ga_ls8c_ard_3'](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3),\n",
    "[BoM Water Data Online](http://www.bom.gov.au/waterdata/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool is used for associating river flow rates with Landsat satellite passes. It filters satellite passes within defined flow bands of interest, removes poor quality satellite data, and also applies a filter to those images on the rising/falling limb. The images are then analysed using the Fisher index and NDWI for water identification in the landscape. \n",
    "The tool outputs the images as NetCDF files for use in GIS software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick use notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **issues relating to the script, a tutorial, or feedback** please contact Martin Job at martin.job@mdba.gov.au or David Weldrake at david.weldrake@mdba.gov.au\n",
    "1. Press shift + enter on cells until a map appears, select the gauge of interest from the map. Make sure to click \"done\" after you have selected your gauge.\n",
    "2. The cell under the map gives you three options for defining the extents of your location of interest. Extents can be defined by uploading a shapefile, typing in the coordinates manually, or using the coordinates of the gauge you selected in the previous step. In this same cell define the flow band of interest.\n",
    "3. Press shift + enter until you get to 'PART 2'. Here you can toggle the satellite passes you wish to analyse and export based on their position on the hydrograph.\n",
    "5. Download the NetCDF files for import into your preferred GIS software, and inspect the thumbail images for each satellite flyover.\n",
    "6. OPTIONAL: download any of the plots of interest.\n",
    "7. OPTIONAL: Download the csv, containing the date of the flyover, gauge reading, and whether you considered it a pass or fail.\n",
    "8. Go back to the gauge selecting map at the top of the page, rerun this cell, and select a new gauge, repeat the process to get this new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Load key Python packages and supporting functions for the analysis. This notebook relies on modules called `dea_bom` and `dea_datahandling`, which are located in the `Scripts` directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2 changes:\n",
    "\n",
    "- Integrate Sentinel 2\n",
    "- Additional band combinations (the burnsie index)\n",
    "- Implementing widgets for user inputs\n",
    "- Moving bulk of code to modules\n",
    "- Automatic uploading to the MDBA arcgis portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import datacube\n",
    "from datacube import Datacube\n",
    "from datacube.utils import geometry \n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.drivers.netcdf import write_dataset_to_netcdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='datacube')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append('../Scripts')\n",
    "from Scripts import dea_bom\n",
    "from Scripts.dea_datahandling import load_ard\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.dates\n",
    "import plotly.offline as py\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "# widgetting:\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arcgis in /env/lib/python3.6/site-packages (1.8.2)\n",
      "Requirement already satisfied: requests-toolbelt in /env/lib/python3.6/site-packages (from arcgis) (0.9.1)\n",
      "Requirement already satisfied: keyring>=19 in /env/lib/python3.6/site-packages (from arcgis) (21.4.0)\n",
      "Requirement already satisfied: requests in /env/lib/python3.6/site-packages (from arcgis) (2.24.0)\n",
      "Requirement already satisfied: six in /env/lib/python3.6/site-packages (from arcgis) (1.15.0)\n",
      "Requirement already satisfied: pyshp>=2 in /env/lib/python3.6/site-packages (from arcgis) (2.1.0)\n",
      "Requirement already satisfied: requests-oauthlib in /env/lib/python3.6/site-packages (from arcgis) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in /env/lib/python3.6/site-packages (from arcgis) (3.2.1)\n",
      "Requirement already satisfied: ipywidgets>=7 in /env/lib/python3.6/site-packages (from arcgis) (7.5.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /env/lib/python3.6/site-packages (from arcgis) (1.19.0)\n",
      "Requirement already satisfied: pandas>=1 in /env/lib/python3.6/site-packages (from arcgis) (1.0.5)\n",
      "Requirement already satisfied: lerc in /env/lib/python3.6/site-packages (from arcgis) (0.1.0)\n",
      "Requirement already satisfied: widgetsnbextension>=3 in /env/lib/python3.6/site-packages (from arcgis) (3.5.1)\n",
      "Requirement already satisfied: requests-ntlm in /env/lib/python3.6/site-packages (from arcgis) (1.1.0)\n",
      "Requirement already satisfied: jupyterlab in /env/lib/python3.6/site-packages (from arcgis) (2.1.3)\n",
      "Requirement already satisfied: SecretStorage>=3; sys_platform == \"linux\" in /env/lib/python3.6/site-packages (from keyring>=19->arcgis) (3.1.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /env/lib/python3.6/site-packages (from keyring>=19->arcgis) (1.7.0)\n",
      "Requirement already satisfied: jeepney>=0.4.2; sys_platform == \"linux\" in /env/lib/python3.6/site-packages (from keyring>=19->arcgis) (0.4.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /env/lib/python3.6/site-packages (from requests->arcgis) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /env/lib/python3.6/site-packages (from requests->arcgis) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /env/lib/python3.6/site-packages (from requests->arcgis) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /env/lib/python3.6/site-packages (from requests->arcgis) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /env/lib/python3.6/site-packages (from requests-oauthlib->arcgis) (3.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /env/lib/python3.6/site-packages (from matplotlib->arcgis) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /env/lib/python3.6/site-packages (from matplotlib->arcgis) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /env/lib/python3.6/site-packages (from matplotlib->arcgis) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /env/lib/python3.6/site-packages (from matplotlib->arcgis) (0.10.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /env/lib/python3.6/site-packages (from ipywidgets>=7->arcgis) (5.3.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /env/lib/python3.6/site-packages (from ipywidgets>=7->arcgis) (4.3.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /env/lib/python3.6/site-packages (from ipywidgets>=7->arcgis) (5.0.7)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /env/lib/python3.6/site-packages (from ipywidgets>=7->arcgis) (7.16.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /env/lib/python3.6/site-packages (from pandas>=1->arcgis) (2020.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /env/lib/python3.6/site-packages (from widgetsnbextension>=3->arcgis) (6.1.3)\n",
      "Requirement already satisfied: ntlm-auth>=1.0.2 in /env/lib/python3.6/site-packages (from requests-ntlm->arcgis) (1.5.0)\n",
      "Requirement already satisfied: cryptography>=1.3 in /env/lib/python3.6/site-packages (from requests-ntlm->arcgis) (3.0)\n",
      "Requirement already satisfied: jupyterlab-server<2.0,>=1.1.0 in /env/lib/python3.6/site-packages (from jupyterlab->arcgis) (1.2.0)\n",
      "Requirement already satisfied: tornado!=6.0.0,!=6.0.1,!=6.0.2 in /env/lib/python3.6/site-packages (from jupyterlab->arcgis) (6.0.4)\n",
      "Requirement already satisfied: jinja2>=2.10 in /env/lib/python3.6/site-packages (from jupyterlab->arcgis) (2.11.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /env/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->keyring>=19->arcgis) (3.1.0)\n",
      "Requirement already satisfied: jupyter-client in /env/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->arcgis) (6.1.6)\n",
      "Requirement already satisfied: decorator in /env/lib/python3.6/site-packages (from traitlets>=4.3.1->ipywidgets>=7->arcgis) (4.4.2)\n",
      "Requirement already satisfied: ipython-genutils in /env/lib/python3.6/site-packages (from traitlets>=4.3.1->ipywidgets>=7->arcgis) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /env/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets>=7->arcgis) (4.6.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /env/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets>=7->arcgis) (3.2.0)\n",
      "Requirement already satisfied: backcall in /env/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7->arcgis) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /env/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7->arcgis) (0.7.5)\n",
      "Requirement already satisfied: pygments in /env/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7->arcgis) (2.6.1)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /env/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7->arcgis) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /env/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7->arcgis) (0.17.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /env/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7->arcgis) (3.0.6)\n",
      "Requirement already satisfied: setuptools>=18.5 in /env/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7->arcgis) (49.6.0)\n",
      "Requirement already satisfied: prometheus-client in /env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3->arcgis) (0.8.0)\n",
      "Requirement already satisfied: nbconvert in /env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3->arcgis) (5.6.1)\n",
      "Requirement already satisfied: Send2Trash in /env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3->arcgis) (1.5.0)\n",
      "Requirement already satisfied: argon2-cffi in /env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3->arcgis) (20.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3->arcgis) (0.8.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3->arcgis) (19.0.2)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /env/lib/python3.6/site-packages (from cryptography>=1.3->requests-ntlm->arcgis) (1.14.2)\n",
      "Requirement already satisfied: json5 in /env/lib/python3.6/site-packages (from jupyterlab-server<2.0,>=1.1.0->jupyterlab->arcgis) (0.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /env/lib/python3.6/site-packages (from jinja2>=2.10->jupyterlab->arcgis) (1.1.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /env/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7->arcgis) (0.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /env/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7->arcgis) (19.3.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /env/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7->arcgis) (0.6.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /env/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7->arcgis) (0.7.1)\n",
      "Requirement already satisfied: wcwidth in /env/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7->arcgis) (0.2.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bleach in /env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension>=3->arcgis) (3.1.5)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension>=3->arcgis) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension>=3->arcgis) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension>=3->arcgis) (1.4.2)\n",
      "Requirement already satisfied: defusedxml in /env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension>=3->arcgis) (0.6.0)\n",
      "Requirement already satisfied: testpath in /env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension>=3->arcgis) (0.4.4)\n",
      "Requirement already satisfied: pycparser in /env/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=1.3->requests-ntlm->arcgis) (2.20)\n",
      "Requirement already satisfied: webencodings in /env/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension>=3->arcgis) (0.5.1)\n",
      "Requirement already satisfied: packaging in /env/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension>=3->arcgis) (20.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Migrating the outputs to the arcgis portal:\n",
    "!pip install arcgis\n",
    "from arcgis.gis import GIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing and loading the gauge information from BOM's Water Data Online "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache\n",
      "4303 stations loaded; e.g.:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[namespace(name='15 MILE @ GRETA STH',\n",
       "           url='http://bom.gov.au/waterdata/services/stations/403213',\n",
       "           pos=(-36.61945775, 146.24407214)),\n",
       " namespace(name='15 MILE @ WANGARATTA',\n",
       "           url='http://bom.gov.au/waterdata/services/stations/403239',\n",
       "           pos=(-36.36666667, 146.2833333)),\n",
       " namespace(name='16 Mile Waterhole',\n",
       "           url='http://bom.gov.au/waterdata/services/stations/913010A',\n",
       "           pos=(-18.876921, 139.360487)),\n",
       " namespace(name='163 Clifton Rd',\n",
       "           url='http://bom.gov.au/waterdata/services/stations/6131318',\n",
       "           pos=(-32.97808, 115.90111)),\n",
       " namespace(name='18 Mile Swamp HorseX',\n",
       "           url='http://bom.gov.au/waterdata/services/stations/144005A',\n",
       "           pos=(-27.49561971, 153.50836409))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_pkl = Path('../Supplementary_data/Inundation_mapping/stations.pkl')\n",
    "\n",
    "# If cache exists, get station data from cache\n",
    "if stations_pkl.exists():\n",
    "    print('Loading from cache')\n",
    "    stations = pickle.load(open(str(stations_pkl), 'rb'))\n",
    "else:\n",
    "    print('Fetching from BoM')\n",
    "    stations = dea_bom.get_stations()\n",
    "    pickle.dump(stations, open(str(stations_pkl), 'wb'))\n",
    "\n",
    "# Filter list to stations with available data\n",
    "stations_with_data = pickle.load(open(str('../Supplementary_data/Inundation_mapping/stations_with_data.pkl'), 'rb'))\n",
    "stations = [i for i in stations if i.name in stations_with_data]\n",
    "\n",
    "# Preview the first five stations loaded\n",
    "print(f'{len(stations)} stations loaded; e.g.:')\n",
    "stations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545e8b005b9c4c7b9f492164d544f065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Map(center=[-34.72, 143.17], controls=(ZoomControl(options=['position', 'zoom_in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gauge_data, station = dea_bom.ui_select_station(stations,\n",
    "                                                zoom=5,\n",
    "                                                center=(-34.72, 143.17));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input user preferences for lat, lon, satellite buffer, and flow thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079e9a740fb04eec8d451842c6566a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HBox(children=(Label(value='1. Set lower and upper flow in ML/Day', style=Descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################################\n",
    "#flow and buffer\n",
    "\n",
    "min_flow = widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=999999,\n",
    "    step=1,\n",
    "    description='Minimum flow:',\n",
    "    disabled=False)\n",
    "\n",
    "max_flow = widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=999999,\n",
    "    step=1,\n",
    "    description='Maximum flow:',\n",
    "    disabled=False)\n",
    "    \n",
    "buffer = widgets.BoundedFloatText(\n",
    "    value=0.2,\n",
    "    min=0,\n",
    "    max=1,\n",
    "    step=0.01,\n",
    "    description='Buffer around location:',\n",
    "    disabled=False,\n",
    "    style = {'description_width': 'initial'}\n",
    ") \n",
    "\n",
    "###############################################################\n",
    "# gauge option\n",
    "check_gauge = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Use gauge location',\n",
    "    disabled=False,\n",
    "    indent=False,\n",
    "    style = {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "\n",
    "use_gauge_location = widgets.Accordion(children=[check_gauge])\n",
    "\n",
    "################################################################\n",
    "# own option\n",
    "check_own = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Define my own location',\n",
    "    disabled=False,\n",
    "    indent=False,\n",
    "    style = {'description_width': 'initial'}\n",
    ")\n",
    "input_lat = widgets.BoundedFloatText(\n",
    "    value=0.0,\n",
    "    min=-99999999999999,\n",
    "    max=999999999999999,\n",
    "    step=0.0001,\n",
    "    description='Latitude:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "input_lon = widgets.BoundedFloatText(\n",
    "    value=0.0,\n",
    "    min=-99999999999999,\n",
    "    max=9999999999999,\n",
    "    step=0.0001,\n",
    "    description='Longitude:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "use_my_own_location = widgets.Accordion(children=[widgets.VBox([check_own,input_lat,input_lon])])\n",
    "\n",
    "##################################################\n",
    "# upload shapefile:\n",
    "check_shapefile = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Upload shapefile for location',\n",
    "    disabled=False,\n",
    "    indent=False,\n",
    "    style = {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "shapefile_loc = widgets.Text(value='shapefile_inputs/',\n",
    "                         placeholder='enter the name of the shapefile in the folder',\n",
    "                         description='String:',\n",
    "                         disabled=False\n",
    "                        )\n",
    "\n",
    "upload_shapefile = widgets.Accordion(children=[widgets.VBox([check_shapefile, shapefile_loc])])\n",
    "\n",
    "\n",
    "################################################\n",
    "# labels:\n",
    "use_gauge_location.set_title(0, 'Use coordinates for the gauge to define extents')\n",
    "use_my_own_location.set_title(0, 'Input coordinates to define extents')\n",
    "upload_shapefile.set_title(0, 'Upload shapefile to define extents')\n",
    "\n",
    "flow_label = widgets.HBox([widgets.Label(value=\"1. Set lower and upper flow in ML/Day\",\n",
    "                                        style = {'description_width': 'initial'},\n",
    "                                        layout = {'color': 'black',\n",
    "                                                'font-weight': 'bold'})])\n",
    "\n",
    "buffer_label = widgets.HBox([widgets.Label(value=\"2. Set buffer around location\",\n",
    "                                            style = {'description_width': 'initial'})])\n",
    "\n",
    "location_label = widgets.HBox([widgets.Label(value= '3. location data source (select one):',\n",
    "                                            style = {'description_width': 'initial'})])\n",
    "\n",
    "#################################################\n",
    "# dashboard:\n",
    "iht_dashboard = widgets.Tab()\n",
    "iht_dashboard.children = [widgets.VBox([flow_label, min_flow, max_flow, buffer_label, buffer, \n",
    "                         location_label,\n",
    "                                        use_gauge_location, use_my_own_location, upload_shapefile])]\n",
    "iht_dashboard.set_title(0, 'IHT Inputs')\n",
    "iht_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow_bounds(user_input_min, user_input_max):\n",
    "    \n",
    "    y_low = user_input_min.value\n",
    "    y_high = user_input_max.value\n",
    "    \n",
    "    return y_low, y_high\n",
    "    \n",
    "def get_coords(gauge_input, self_input, user_lat, user_lon, shape_input, shapefile_path,\n",
    "              buffer, station_loc):\n",
    "    \n",
    "    if sum([gauge_input, self_input, shape_input]) > 1:\n",
    "        return 'ERROR: More than one location source defined'\n",
    "    \n",
    "    if gauge_input == True:\n",
    "            \n",
    "        lat, lon = station_loc\n",
    "        lat_low = round((lat - buffer), 2)\n",
    "        lat_high = round((lat + buffer), 2)\n",
    "        lon_low = round((lon - buffer), 2)\n",
    "        lon_high = round((lon + buffer), 2)\n",
    "        \n",
    "        return lat_low, lat_high, lon_low, lon_high\n",
    "        \n",
    "    if self_input == True:\n",
    "        lat = user_lat\n",
    "        lon = user_lon\n",
    "        lat_low = round((lat - buffer), 2)\n",
    "        lat_high = round((lat + buffer), 2)\n",
    "        lon_low = round((lon - buffer), 2)\n",
    "        lon_high = round((lon + buffer), 2)\n",
    "        \n",
    "        return lat_low, lat_high, lon_low, lon_high\n",
    "    \n",
    "    if shape_input == True:\n",
    "        vector_file = shapefile_loc\n",
    "        gdf = gpd.read_file(vector_file)\n",
    "        lon_low = round(gdf.bounds.minx,2)\n",
    "        lon_high = round(gdf.bounds.maxx,2)\n",
    "        lat_low = round(gdf.bounds.miny,2)\n",
    "        lat_high = round(gdf.bounds.maxy, 2)\n",
    "        \n",
    "        return lat_low, lat_high, lon_low, lon_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaxis_lower_parameter, yaxis_higher_parameter = get_flow_bounds(min_flow, max_flow)\n",
    "\n",
    "lat_low, lat_high, lon_low, lon_high = get_coords(check_gauge.value,\n",
    "                                                  check_own.value,\n",
    "                                                  input_lat.value,\n",
    "                                                  input_lon.value,\n",
    "                                                  check_shapefile.value, \n",
    "                                                  shapefile_loc.value, \n",
    "                                                  buffer.value,\n",
    "                                                  station.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Landsat passes for the location of interest\n",
    "\n",
    "The second cell in this block will take up to 5 minutes to run, as it is loading the satellite passes, applying a cloud filter and filtering out passes with poor coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_dc = datacube.Datacube(app='Loading Landsat IHT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_date = str(datetime.today().strftime('%Y-%m-%d')) # Convert to widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/remote_sensing_team/Inundation_History_Tool/Main/Scripts/dea_datahandling.py:238: UserWarning:\n",
      "\n",
      "Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 782 out of 1083 time steps with at least 60.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 782 time steps as a dask array\n"
     ]
    }
   ],
   "source": [
    "landsat_query = {\n",
    "    'x': (lon_low, lon_high),\n",
    "    'y': (lat_low, lat_high),\n",
    "    'time': ('1988-01-01', todays_date),\n",
    "    'measurements': [\"nbart_red\"],\n",
    "    'output_crs': 'EPSG:3577',\n",
    "    'resolution': (-30, 30),\n",
    "    'group_by': 'solar_day'\n",
    "}\n",
    "\n",
    "# Load available data from all three Landsat satellites using the above query\n",
    "# Please note the two available options below. You can uncomment the min_gooddata and \n",
    "# change this value to reflect the minimum good quality pixels to include (0.6 = 60%)\n",
    "# Changing the ls7_slc_off variable to True will include ls7 passes with the slc failure\n",
    "landsat_ds = load_ard(dc=landsat_dc, \n",
    "              products=['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3'],\n",
    "              mask_pixel_quality=True,\n",
    "              min_gooddata=0.60, #Toggle number between 0 and 1 (default is 0.6)\n",
    "              ls7_slc_off=False, # Change to True to include Ls7 passes with slc failure\n",
    "              dask_chunks={}, \n",
    "              **landsat_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/remote_sensing_team/Inundation_History_Tool/Main/Scripts/dea_datahandling.py:238: UserWarning:\n",
      "\n",
      "Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 360 out of 452 time steps with at least 10.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 360 time steps as a dask array\n"
     ]
    }
   ],
   "source": [
    "sentinel_dc = datacube.Datacube(app='Loading sentinel IHT')\n",
    "\n",
    "sentinel_query = {\n",
    "    'x': (lon_low, lon_high),\n",
    "    'y': (lat_low, lat_high),\n",
    "    'time': ('2015-06-23', todays_date),\n",
    "    'measurements': ['nbart_red'],\n",
    "    'output_crs': 'EPSG:3577',\n",
    "    'resolution': (-10, 10),\n",
    "    'group_by': 'solar_day'\n",
    "}\n",
    "\n",
    "# Load available data from both Sentinel 2 satellites\n",
    "sentinel_ds = load_ard(dc=sentinel_dc,\n",
    "              products=['s2a_ard_granule', 's2b_ard_granule'],\n",
    "              min_gooddata=0.10,\n",
    "              mask_pixel_quality=True,         \n",
    "              dask_chunks={},\n",
    "              **sentinel_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out passes for dates within the flow bands of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauge_data_cleaner(input_data):\n",
    "    '''Ingests a pd.df of flow timeseries, \n",
    "    converts data types and measurements,\n",
    "    returns clean gauge data'''\n",
    "    gauge_df = input_data.copy(deep = True)\n",
    "    gauge_df[\"Value\"] = pd.to_numeric(gauge_df[\"Value\"], downcast=\"float\")\n",
    "    gauge_df['Value'] = gauge_df['Value']*86.4\n",
    "    gauge_df.index = gauge_df.index.normalize()\n",
    "    \n",
    "    return gauge_df\n",
    "\n",
    "clean_gauge_data = gauge_data_cleaner(gauge_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_satellite_with_gauge(sat_input, gauge_input):\n",
    "    '''Ingests gauge data and satellite data xr,\n",
    "    identifies where on the gauge data there are passes,\n",
    "    returns these dates\n",
    "    '''\n",
    "    gauge_data_xr = gauge_input.to_xarray() \n",
    "    merged_data = gauge_data_xr.interp(Timestamp=sat_input.time)\n",
    "    specified_satellite_passes = merged_data.where(((merged_data.Value > yaxis_lower_parameter) & (merged_data.Value < yaxis_higher_parameter)), drop=True)\n",
    "    specified_satellite_passes = specified_satellite_passes.drop('Timestamp')\n",
    "    date_list = specified_satellite_passes.time.values\n",
    "    \n",
    "    how_many = specified_satellite_passes.time.shape[0]\n",
    "    \n",
    "    return date_list, how_many, merged_data\n",
    "\n",
    "ls_date_list, ls_count, ls_merged_data = merge_satellite_with_gauge(landsat_ds, clean_gauge_data)  \n",
    "s_date_list, s_count, s_merged_data = merge_satellite_with_gauge(sentinel_ds, clean_gauge_data)\n",
    "\n",
    "#Check how many passes you are about to load. Loading over 400 passes may cause the kernal to crash\n",
    "print(\"You are about to load {} landsat passes\".format(ls_count))\n",
    "print(\"You are about to load {} sentinel passes\".format(s_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_passes(input_sat_passes, input_date_list):\n",
    "    '''Ingests satellite data dask array and the required dates,\n",
    "    computes the dask array for these dates only'''\n",
    "    \n",
    "    computed = input_sat_passes.sel(time=input_date_list).compute()\n",
    "    \n",
    "    return computed\n",
    "    \n",
    "ls_specified_passes = compute_passes(landsat_ds, ls_date_list)\n",
    "s_specified_passes = compute_passes(sentinel_ds, s_date_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the satellite passes with the gauge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pandas(input_merged_data, input_specified_passes):\n",
    "    ''' Add description '''\n",
    "    merged_data_pd = input_merged_data.to_dataframe()\n",
    "    \n",
    "    all_specified_passes_pd = input_specified_passes.time.to_dataframe()\n",
    "    all_specified_passes_pd = all_specified_passes_pd.rename(columns = {'time': 'date'})#can't have 2 columns called time\n",
    "\n",
    "    all_merged_data = pd.merge(all_specified_passes_pd, merged_data_pd, left_on= 'time', \n",
    "                                right_index=True, how='inner')\n",
    "    all_merged_data = all_merged_data.drop(columns='date')\n",
    "    all_merged_data = all_merged_data.drop(columns='Timestamp')\n",
    "    all_merged_data.index = all_merged_data.index.normalize()\n",
    "    all_merged_data.index.name = 'date'\n",
    "    \n",
    "    return all_merged_data\n",
    "    \n",
    "ls_all_merged_data = convert_to_pandas(ls_merged_data, ls_specified_passes)\n",
    "s_all_merged_data = convert_to_pandas(s_merged_data, s_specified_passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_flow_bands_to_gauge_data(input_gauge_data):\n",
    "    ''' Add description - shift to main gauge function - check for bugs before '''\n",
    "\n",
    "    graph_gauge_df = input_gauge_data.copy(deep=True)\n",
    "    \n",
    "    graph_gauge_df['y_lower'] = yaxis_lower_parameter\n",
    "    graph_gauge_df['y_higher'] = yaxis_higher_parameter\n",
    "    \n",
    "    return graph_gauge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_all(input_gauge_data, input_ls, input_s):\n",
    "    ''' Add description '''\n",
    "    \n",
    "    # Set up the dataframe:\n",
    "    graph_gauge_df = add_flow_bands_to_gauge_data(input_gauge_data)\n",
    "    \n",
    "    fig_all = go.Figure()\n",
    "    \n",
    "    # Add gauge data:\n",
    "    fig_all.add_trace(go.Scatter(name = 'Gauge data',\n",
    "                                x = graph_gauge_df.index,\n",
    "                                y = graph_gauge_df['Value'],\n",
    "                                mode = 'lines',\n",
    "                                line = dict(color = 'royalblue', width = 1),\n",
    "                                hovertemplate = 'flow: %{y:.2f}<extra></extra>' +\n",
    "                                 '<br><b>Date</b>: %{x}<br>'\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    # Add landsat:\n",
    "    fig_all.add_trace(go.Scatter(name = 'Landsat pass',\n",
    "                                x = input_ls.index,\n",
    "                                y = input_ls['Value'],\n",
    "                                mode = 'markers',\n",
    "                                line = dict(color = 'green', width = 2), \n",
    "                                hovertemplate = 'Landsat pass <extra></extra>' +\n",
    "                                '<br><b>Date</b>: %{x}<br>',\n",
    "                                marker_size = 9\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    # Add sentinel:\n",
    "    fig_all.add_trace(go.Scatter(name = 'Sentinel pass',\n",
    "                                x = input_s.index,\n",
    "                                y = input_s['Value'],\n",
    "                                mode = 'markers',\n",
    "                                line = dict(color = 'lightseagreen', width = 2), \n",
    "                                hovertemplate = 'Sentinel pass <extra></extra>' +\n",
    "                                 '<br><b>Date</b>: %{x}<br>',\n",
    "                                marker_symbol = 'cross',\n",
    "                                marker_size = 9\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    # Adding the lower flow bounds:\n",
    "    fig_all.add_trace(go.Scatter(name = 'lower flow bound',\n",
    "                                x = graph_gauge_df.index,\n",
    "                                y = graph_gauge_df['y_lower'],\n",
    "                                mode = 'lines',\n",
    "                                line = dict(color = 'black', width = 2)\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    # Adding the upper flow bounds:\n",
    "    fig_all.add_trace(go.Scatter(name = 'upper flow bound',\n",
    "                                x = graph_gauge_df.index,\n",
    "                                y = graph_gauge_df['y_higher'],\n",
    "                                mode = 'lines',\n",
    "                                line = dict(color = 'black', width = 2)\n",
    "                                )\n",
    "                     )\n",
    "\n",
    "    fig_all.update_layout(hovermode=\"closest\",\n",
    "                                     title= 'Landsat and Sentinel passes within the flow band of interest',\n",
    "                                     xaxis_title='Date',\n",
    "                                     yaxis_title='Flow at gauge (ML/Day)',\n",
    "                                     font=dict(family='Calibri', size=16, color='black'),\n",
    "                                     paper_bgcolor='white',\n",
    "                                     plot_bgcolor='white',\n",
    "                                     hoverlabel=dict(\n",
    "                                         bgcolor=\"white\",\n",
    "                                         font_size=16,\n",
    "                                         font_family=\"Rockwell\")) \n",
    "    \n",
    "    return fig_all\n",
    "\n",
    "graph_all(clean_gauge_data, ls_all_merged_data, s_all_merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now separate the gauge data into 2 lists: rising and falling. Check the graph in the output to see how well the data was separated\n",
    "\n",
    "This box will check whether the gauge-reading 21 (can change with user input) days after the satellite pass was higher or lower than the day of the satellite pass. The multiplier represents by how much more the water should be lower or higher to be considered a significant change. This has been defined as 1 for simplicity (can also change with user input). It puts the pass either into the rising or falling list accordingly. It runs a loop to do this for every single pass. The output will tell you how many passes you got in each list and show you how the passes were catagorised on a hydrogaph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rising_falling_main(multiplier, days_ahead, input_gauge_df, input_sat_passes):\n",
    "    ''' Add description '''\n",
    "\n",
    "    rising_list = list()\n",
    "    falling_list = list()\n",
    "    \n",
    "    for i, flow in enumerate(input_gauge_df['Value'][:len(input_gauge_df['Value'])-days_ahead]):\n",
    "        if flow < input_gauge_df['Value'][i + days_ahead] * multiplier:\n",
    "            rising_list.append(input_gauge_df.index[i])\n",
    "        else:\n",
    "            falling_list.append(input_gauge_df.index[i])\n",
    "    \n",
    "    rising_passes = list(set(rising_list) & set(list(input_sat_passes.index)))\n",
    "    falling_passes = list(set(falling_list) & set(list(input_sat_passes.index)))\n",
    "\n",
    "    rising_passes_df = df_constructor(rising_passes, input_sat_passes)\n",
    "    falling_passes_df = df_constructor(falling_passes, input_sat_passes)\n",
    "    \n",
    "    return rising_passes_df, falling_passes_df\n",
    "\n",
    "def df_constructor(input_list, sat_data_to_join):\n",
    "    df = pd.DataFrame(input_list, columns = ['date'])\n",
    "    df['date'] = pd.to_datetime(df['date'], format = '%Y-%m-%d')\n",
    "    df = df.set_index('date')\n",
    "    df = df.join(sat_data_to_join)\n",
    "    \n",
    "    return df\n",
    "\n",
    "multiplier = 1 # how much more the flow rate has to rise by to be considered a significant rise\n",
    "days_ahead = 21 # how many days in advance the algorithm checks for a rise or fall\n",
    "\n",
    "ls_rising, ls_falling = rising_falling_main(multiplier, days_ahead, clean_gauge_data, ls_all_merged_data)\n",
    "s_rising, s_falling = rising_falling_main(multiplier, days_ahead, clean_gauge_data, s_all_merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_rising_falling(input_gauge_data, input_rising_ls, input_falling_ls, input_rising_s, \n",
    "                         input_falling_s):\n",
    "    \n",
    "    graph_gauge_df = add_flow_bands_to_gauge_data(input_gauge_data)\n",
    "    \n",
    "    fig_rising_falling = go.Figure()\n",
    "    \n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'Gauge data',\n",
    "                                           x = graph_gauge_df.index,\n",
    "                                           y = graph_gauge_df['Value'],\n",
    "                                           mode = 'lines',\n",
    "                                           line = dict(color = 'royalblue', width = 1),\n",
    "                                           hovertemplate = 'flow: %{y:.2f}<extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>'\n",
    "                                           )\n",
    "                                )\n",
    "    \n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'Rising Landsat pass',\n",
    "                                           x = input_rising_ls.index,\n",
    "                                           y = input_rising_ls['Value'],\n",
    "                                           mode = 'markers',\n",
    "                                           marker_symbol = 'triangle-up',\n",
    "                                           marker_size = 9,\n",
    "                                           line = dict(color = 'green', width = 2),\n",
    "                                           hovertemplate = 'Rising Landsat pass <extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>'\n",
    "                                           )\n",
    "                                ) \n",
    "    \n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'Falling Landsat pass',\n",
    "                                           x = input_falling_ls.index,\n",
    "                                           y = input_falling_ls['Value'],\n",
    "                                           mode = 'markers',\n",
    "                                           marker_symbol = 'triangle-down',\n",
    "                                           marker_size = 9,\n",
    "                                           line = dict(color = 'crimson', width = 2),\n",
    "                                           hovertemplate = 'Falling Landsat pass <extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>'\n",
    "                                           )\n",
    "                                ) \n",
    "    \n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'Rising Sentinel pass',\n",
    "                                           x = input_rising_s.index,\n",
    "                                           y = input_rising_s['Value'],\n",
    "                                           mode = 'markers',\n",
    "                                           marker_symbol = 'star-triangle-up',\n",
    "                                           marker_size = 9,\n",
    "                                           line = dict(color = 'lightseagreen', width = 2),\n",
    "                                           hovertemplate = 'Rising Sentinel pass <extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>'\n",
    "                                           )\n",
    "                                ) \n",
    "        \n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'Falling Sentinel pass',\n",
    "                                           x = input_falling_s.index,\n",
    "                                           y = input_falling_s['Value'],\n",
    "                                           mode = 'markers',\n",
    "                                           marker_symbol = 'star-triangle-down',\n",
    "                                           marker_size = 9,\n",
    "                                           line = dict(color = 'purple', width = 2),\n",
    "                                           hovertemplate = 'Falling Sentinel pass <extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>'\n",
    "                                           )\n",
    "                                ) \n",
    "    \n",
    "    # Adding the lower flow bounds:\n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'lower flow bound',\n",
    "                                x = graph_gauge_df.index,\n",
    "                                y = graph_gauge_df['y_lower'],\n",
    "                                mode = 'lines',\n",
    "                                line = dict(color = 'black', width = 2)\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    # Adding the upper flow bounds:\n",
    "    fig_rising_falling.add_trace(go.Scatter(name = 'upper flow bound',\n",
    "                                x = graph_gauge_df.index,\n",
    "                                y = graph_gauge_df['y_higher'],\n",
    "                                mode = 'lines',\n",
    "                                line = dict(color = 'black', width = 2)\n",
    "                                )\n",
    "                     )\n",
    "    \n",
    "    fig_rising_falling.update_layout(hovermode=\"closest\",\n",
    "                                 title= 'Sentinel and Landsat broken into rising/falling categories',\n",
    "                                 xaxis_title='Date',\n",
    "                                 yaxis_title='Flow at gauge (ML/Day)',\n",
    "                                 font=dict(family='Calibri', size=16, color='black'),\n",
    "                                 paper_bgcolor='white',\n",
    "                                 plot_bgcolor='white',\n",
    "                                 hoverlabel=dict(\n",
    "                                     bgcolor=\"white\",\n",
    "                                     font_size=16,\n",
    "                                     font_family=\"Rockwell\")\n",
    "                                    ) \n",
    "    \n",
    "    return fig_rising_falling\n",
    "\n",
    "\n",
    "print(\"{} rising landsat passes\".format(len(ls_rising)))\n",
    "print(\"{} falling landsat passes\".format(len(ls_falling)))\n",
    "print(\"{} rising sentinel passes\".format(len(s_rising)))\n",
    "print(\"{} falling sentinel passes\".format(len(s_falling)))\n",
    "graph_rising_falling(clean_gauge_data, ls_rising, ls_falling, s_rising, s_falling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rising_falling_cleaner(input_df, sat_source, pass_or_fail):\n",
    "    ''' Add Description '''\n",
    "    \n",
    "    df = input_df.copy(deep = True)\n",
    "    \n",
    "    df = df.drop(['spatial_ref_x', 'spatial_ref_y'], axis = 1)\n",
    "    df['combined'] = str(sat_source + ' ' + pass_or_fail)\n",
    "    \n",
    "    return df\n",
    "\n",
    "ls_rising_clean = rising_falling_cleaner(ls_rising, 'landsat', 'accept')\n",
    "ls_falling_clean = rising_falling_cleaner(ls_falling, 'landsat', 'reject')\n",
    "s_rising_clean = rising_falling_cleaner(s_rising, 'sentinel', 'accept')\n",
    "s_falling_clean = rising_falling_cleaner(s_falling, 'sentinel', 'reject')\n",
    "    \n",
    "master_df = pd.concat([ls_rising_clean, ls_falling_clean, s_rising_clean, s_falling_clean])\n",
    "ls_only = pd.concat([ls_rising_clean, ls_falling_clean])\n",
    "s_only = pd.concat([s_rising_clean, s_falling_clean])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - Outputting the maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual check of satellite passes you would like to analyse\n",
    "The program has split the satellite passes into the rising and falling limb and allocated them to a 'pass' and 'fail' category respectively. Only the satellite passes in the 'pass' category will be analysed. View the graph below, and click on the satellite passes you would like the reclassify, and the program will reclassify them for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_reindex = master_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_colour(x):\n",
    "    # Function to allocate a colour to the \n",
    "    # sat pass depending on how it is classified\n",
    "    if (x == 'landsat accept'):    \n",
    "        return 'green'\n",
    "    elif (x == 'landsat reject'):\n",
    "        return 'red'\n",
    "    elif (x == 'sentinel accept'):\n",
    "        return 'purple'\n",
    "    else:\n",
    "        return 'lightpink' \n",
    "\n",
    "graph_gauge_df = add_flow_bands_to_gauge_data(clean_gauge_data)\n",
    "\n",
    "# Adding landsat trace:\n",
    "trace_sats = go.Scatter(name = 'Satellite pass',\n",
    "                      x = master_df_reindex['date'],\n",
    "                      y = master_df_reindex['Value'],\n",
    "                      mode = 'markers',\n",
    "                      marker = dict(size=8,\n",
    "                                    color=list(map(set_colour, master_df_reindex['combined']))),\n",
    "                      marker_style = dict(size=8,\n",
    "                                    color=list(map(set_colour, master_df_reindex['combined']))),\n",
    "                      showlegend = False\n",
    "                     )  \n",
    "\n",
    "# Adding the gauge data:\n",
    "trace_gauge = go.Scatter(name = 'Gauge data',\n",
    "                     x = graph_gauge_df.index,\n",
    "                     y = graph_gauge_df['Value'],\n",
    "                     mode = 'lines',\n",
    "                     line = dict(color = 'royalblue', width = 1),\n",
    "                     hovertemplate = 'flow: %{y:.2f}<extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>')\n",
    "\n",
    "# Adding the lower flow bounds:\n",
    "trace_lower = go.Scatter(name = 'lower flow bound',\n",
    "                     x = graph_gauge_df.index,\n",
    "                     y = graph_gauge_df['y_lower'],\n",
    "                     mode = 'lines',\n",
    "                     line = dict(color = 'black', width = 2)\n",
    "                    )\n",
    "\n",
    "# Adding the upper flow bounds:\n",
    "trace_upper = go.Scatter(name = 'upper flow bound',\n",
    "                     x = graph_gauge_df.index,\n",
    "                     y = graph_gauge_df['y_higher'],\n",
    "                     mode = 'lines',\n",
    "                     line = dict(color = 'black', width = 2)\n",
    "                    )\n",
    "# Adding for legend\n",
    "trace_pass_ls = go.Scatter(name = 'landsat accepted',\n",
    "                     x=[None], y=[None],\n",
    "                     mode = 'markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'green'),\n",
    "                     showlegend = True)\n",
    "\n",
    "# Adding for legend\n",
    "trace_fail_ls = go.Scatter(name = 'landsat rejected', \n",
    "                     x=[None], y=[None],\n",
    "                     mode= ' markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'red'),\n",
    "                     showlegend = True)\n",
    "\n",
    "trace_pass_s = go.Scatter(name = 'sentinel accepted',\n",
    "                     x=[None], y=[None],\n",
    "                     mode = 'markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'purple'),\n",
    "                     showlegend = True)\n",
    "\n",
    "# Adding for legend\n",
    "trace_fail_s = go.Scatter(name = 'sentinel rejected', \n",
    "                     x=[None], y=[None],\n",
    "                     mode= ' markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'lightpink'),\n",
    "                     showlegend = True)\n",
    "\n",
    "# Add the traces to the figure:\n",
    "passing_failing_graph = go.FigureWidget(data=[trace_sats, trace_gauge, \n",
    "                                              trace_lower, trace_upper, \n",
    "                                              trace_pass_ls, trace_fail_ls,\n",
    "                                              trace_pass_s, trace_fail_s])\n",
    "\n",
    "passing_failing_graph.update_layout(hovermode=\"closest\",\n",
    "                          title= 'Proposed satellite passes to use in the analysis',\n",
    "                          xaxis_title='Date',\n",
    "                          yaxis_title='Flow at gauge (ML/Day)',\n",
    "                          font=dict(family='Calibri', size=16, color='black'),\n",
    "                          paper_bgcolor='white',\n",
    "                          plot_bgcolor='white',\n",
    "                          hoverlabel=dict(\n",
    "                              bgcolor=\"white\",\n",
    "                              font_size=16,\n",
    "                              font_family=\"Rockwell\")) \n",
    "\n",
    "scatter = passing_failing_graph.data[0]\n",
    "\n",
    "def update_point(trace, points, selector):\n",
    "    ''' Reclassify the points based on user selection '''\n",
    "    \n",
    "    try:\n",
    "        date = points.xs[0]\n",
    "        row_name = master_df_reindex.loc[master_df_reindex['date'] == date]\n",
    "        \n",
    "        if date in ls_only.index and date in s_only.index:\n",
    "            if 'accept' in row_name['combined'].iloc[0]:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'landsat reject'\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'sentinel reject'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the landsat and sentinel pass on ', date, ' has been reclassified to be rejected')\n",
    "            else:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'landsat accept'\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'sentinel accept'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the landsat and sentinel pass on ', date, ' has been reclassified to be accepted')\n",
    "        \n",
    "        elif date in ls_only.index and date not in s_only.index:\n",
    "            if row_name['combined'].iloc[0] == 'landsat accept':\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'landsat reject'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the landsat pass on ', date, ' has been reclassified to be rejected')\n",
    "            else:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'landsat accept'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the landsat pass on ', date, ' has been reclassified to be accepted')\n",
    "                \n",
    "        elif date in s_only.index and date not in ls_only.index:\n",
    "            if row_name['combined'].iloc[0] == 'sentinel accept':\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'sentinel reject'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the sentinel pass on ', date, ' has been reclassified to be rejected')\n",
    "            else:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'sentinel accept'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the sentinel pass on ', date, ' has been reclassified to be accepted')\n",
    "                \n",
    "    except IndexError:\n",
    "        print('You missed the satellite pass! Try click again')   \n",
    "\n",
    "scatter.on_click(update_point)\n",
    "\n",
    "passing_failing_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_colour(x):\n",
    "    # Function to allocate a colour to the \n",
    "    # sat pass depending on how it is classified\n",
    "    if (x == 'landsat accept'):    \n",
    "        return 'green'\n",
    "    elif (x == 'landsat reject'):\n",
    "        return 'red'\n",
    "    elif (x == 'sentinel accept'):\n",
    "        return 'purple'\n",
    "    else:\n",
    "        return 'lightpink' \n",
    "\n",
    "graph_gauge_df = add_flow_bands_to_gauge_data(clean_gauge_data)\n",
    "\n",
    "# Adding landsat trace:\n",
    "trace_sats = go.Scatter(name = 'Satellite pass',\n",
    "                      x = master_df_reindex['date'],\n",
    "                      y = master_df_reindex['Value'],\n",
    "                      mode = 'markers',\n",
    "                      marker = dict(size=8,\n",
    "                                    color=list(map(set_colour, master_df_reindex['combined']))),\n",
    "                      showlegend = False\n",
    "                     )  \n",
    "\n",
    "# Adding the gauge data:\n",
    "trace_gauge = go.Scatter(name = 'Gauge data',\n",
    "                     x = graph_gauge_df.index,\n",
    "                     y = graph_gauge_df['Value'],\n",
    "                     mode = 'lines',\n",
    "                     line = dict(color = 'royalblue', width = 1),\n",
    "                     hovertemplate = 'flow: %{y:.2f}<extra></extra>' +\n",
    "                                            '<br><b>Date</b>: %{x}<br>')\n",
    "\n",
    "# Adding the lower flow bounds:\n",
    "trace_lower = go.Scatter(name = 'lower flow bound',\n",
    "                     x = graph_gauge_df.index,\n",
    "                     y = graph_gauge_df['y_lower'],\n",
    "                     mode = 'lines',\n",
    "                     line = dict(color = 'black', width = 2)\n",
    "                    )\n",
    "\n",
    "# Adding the upper flow bounds:\n",
    "trace_upper = go.Scatter(name = 'upper flow bound',\n",
    "                     x = graph_gauge_df.index,\n",
    "                     y = graph_gauge_df['y_higher'],\n",
    "                     mode = 'lines',\n",
    "                     line = dict(color = 'black', width = 2)\n",
    "                    )\n",
    "# Adding for legend\n",
    "trace_pass_ls = go.Scatter(name = 'landsat accepted',\n",
    "                     x=[None], y=[None],\n",
    "                     mode = 'markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'green'),\n",
    "                     showlegend = True)\n",
    "\n",
    "# Adding for legend\n",
    "trace_fail_ls = go.Scatter(name = 'landsat rejected', \n",
    "                     x=[None], y=[None],\n",
    "                     mode= ' markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'red'),\n",
    "                     showlegend = True)\n",
    "\n",
    "trace_pass_s = go.Scatter(name = 'sentinel accepted',\n",
    "                     x=[None], y=[None],\n",
    "                     mode = 'markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'purple'),\n",
    "                     showlegend = True)\n",
    "\n",
    "# Adding for legend\n",
    "trace_fail_s = go.Scatter(name = 'sentinel rejected', \n",
    "                     x=[None], y=[None],\n",
    "                     mode= ' markers',\n",
    "                     marker = dict(size=8,\n",
    "                                   color= 'lightpink'),\n",
    "                     showlegend = True)\n",
    "\n",
    "# Add the traces to the figure:\n",
    "passing_failing_graph = go.FigureWidget(data=[trace_sats, trace_gauge, \n",
    "                                              trace_lower, trace_upper, \n",
    "                                              trace_pass_ls, trace_fail_ls,\n",
    "                                              trace_pass_s, trace_fail_s])\n",
    "\n",
    "passing_failing_graph.update_layout(hovermode=\"closest\",\n",
    "                          title= 'Proposed satellite passes to use in the analysis',\n",
    "                          xaxis_title='Date',\n",
    "                          yaxis_title='Flow at gauge (ML/Day)',\n",
    "                          font=dict(family='Calibri', size=16, color='black'),\n",
    "                          paper_bgcolor='white',\n",
    "                          plot_bgcolor='white',\n",
    "                          hoverlabel=dict(\n",
    "                              bgcolor=\"white\",\n",
    "                              font_size=16,\n",
    "                              font_family=\"Rockwell\")) \n",
    "\n",
    "scatter = passing_failing_graph.data[0]\n",
    "\n",
    "def update_point(trace, points, selector):\n",
    "    ''' Reclassify the points based on user selection '''\n",
    "    \n",
    "    try:\n",
    "        date = points.xs[0]\n",
    "        row_name = master_df_reindex.loc[master_df_reindex['date'] == date]\n",
    "        \n",
    "        if date in ls_only.index and date in s_only.index:\n",
    "            if 'accept' in row_name['combined'].iloc[0]:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'landsat reject'\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'sentinel reject'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the landsat and sentinel pass on ', date, ' has been reclassified to be rejected')\n",
    "            else:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'landsat accept'\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'sentinel accept'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the landsat and sentinel pass on ', date, ' has been reclassified to be accepted')\n",
    "        \n",
    "        elif date in ls_only.index and date not in s_only.index:\n",
    "            if row_name['combined'].iloc[0] == 'landsat accept':\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'landsat reject'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the landsat pass on ', date, ' has been reclassified to be rejected')\n",
    "            else:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'landsat accept'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the landsat pass on ', date, ' has been reclassified to be accepted')\n",
    "                \n",
    "        elif date in s_only.index and date not in ls_only.index:\n",
    "            if row_name['combined'].iloc[0] == 'sentinel accept':\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'sentinel reject'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the sentinel pass on ', date, ' has been reclassified to be rejected')\n",
    "            else:\n",
    "                master_df_reindex.loc[master_df_reindex['date'] == date, 'combined'] = 'sentinel accept'\n",
    "                with passing_failing_graph.batch_update():\n",
    "                    scatter.marker.color = list(map(set_colour, master_df_reindex['combined']))\n",
    "                print('the sentinel pass on ', date, ' has been reclassified to be accepted')\n",
    "                \n",
    "    except IndexError:\n",
    "        print('You missed the satellite pass! Try click again')   \n",
    "\n",
    "scatter.on_click(update_point)\n",
    "\n",
    "passing_failing_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get only acceptable passes:\n",
    "passes_only = master_df_reindex[master_df_reindex['combined'].str.contains('accept')]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_of_interest = passes_only['date'].values\n",
    "sat_source = passes_only['combined'].values\n",
    "\n",
    "for i, day in enumerate(dates_of_interest):\n",
    "    \n",
    "    print(i)   \n",
    "    date_string = str(passes_only['date'].iloc[i].date())\n",
    "    print(date_string)\n",
    "    \n",
    "    if sat_source[i] == 'landsat accept':\n",
    "\n",
    "        file_extension = '.nc'\n",
    "        file_name = 'netcdf_outputs/' + date_string + 'landsat' + file_extension\n",
    "        # Create a reusable query\n",
    "        landsat_data_query = {\n",
    "            'x': (lon_low, lon_high),\n",
    "            'y': (lat_low, lat_high),\n",
    "            'time': (date_string),\n",
    "            'measurements': ['nbart_red', 'nbart_green', 'nbart_blue', \n",
    "                             'nbart_nir', 'nbart_swir_1', 'nbart_swir_2'],\n",
    "            'output_crs': 'EPSG:3577',\n",
    "            'resolution': (-30, 30),\n",
    "            'group_by': 'solar_day'\n",
    "        }\n",
    "\n",
    "        # Load available data from all three Landsat satellites\n",
    "        ls_ds = load_ard(dc=landsat_dc, \n",
    "                      products=['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3'],\n",
    "                      mask_pixel_quality=True,\n",
    "                      min_gooddata=0.60,\n",
    "                      ls7_slc_off=False, ## comment this to keep the images with the SLC error\n",
    "                      **landsat_data_query)\n",
    "\n",
    "        # Shows an RGB thumbnail of each pass:\n",
    "        ls_ds[['nbart_red', 'nbart_green', 'nbart_blue']].isel(time=0).to_array().plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Making an NDWI layer and showing a thumbnail of the output\n",
    "        ds_ndwi = (ls_ds.nbart_nir - ls_ds.nbart_swir_1) /(ls_ds.nbart_nir + ls_ds.nbart_swir_1)\n",
    "        ls_ds[\"NDWI\"] = ds_ndwi\n",
    "        ls_ds['NDWI'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Making the fisher index layer and showing a thumbnail of the output\n",
    "        ds_fisher = 1.7204+(171*ls_ds.nbart_green)+(3*ls_ds.nbart_red)-(70*ls_ds.nbart_nir)-(45*ls_ds.nbart_swir_1)-(71*ls_ds.nbart_swir_2)\n",
    "        ls_ds['Fisher'] = ds_fisher  \n",
    "        ls_ds['Fisher'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        ds_burnsie = (ls_ds.nbart_swir_2 + ls_ds.nbart_nir + ls_ds.nbart_red)\n",
    "        ls_ds['Burnsie'] = ds_burnsie \n",
    "        ls_ds['Burnsie'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Write the layers to a NetCDF, ready for importing\n",
    "        try:\n",
    "            write_dataset_to_netcdf(ls_ds, file_name)\n",
    "        except RuntimeError:\n",
    "            print('***THIS FILE NAME ALREADY EXISTS, PLEASE SAVE YOUR NETCDF FILES TO ANOTHER DIRECTORY***')\n",
    "            break\n",
    "            \n",
    "    ########################################                \n",
    "    elif sat_source[i] == 'sentinel accept':\n",
    "        \n",
    "        file_extension = '.nc'\n",
    "        file_name = 'netcdf_outputs/' + date_string + 'sentinel' + file_extension\n",
    "        # Create a reusable query\n",
    "        sentinel_data_query = {\n",
    "            'x': (lon_low, lon_high),\n",
    "            'y': (lat_low, lat_high),\n",
    "            'time': (date_string),\n",
    "            'measurements': ['nbart_red', 'nbart_green', 'nbart_blue', \n",
    "                             'nbart_nir_1', 'nbart_swir_2', 'nbart_swir_3'],\n",
    "            'output_crs': 'EPSG:3577',\n",
    "            'resolution': (-10, 10),\n",
    "            'group_by': 'solar_day'\n",
    "        }\n",
    "\n",
    "        # Load available data from all three Landsat satellites\n",
    "        s_ds = load_ard(dc=sentinel_dc,\n",
    "                      products=['s2a_ard_granule', 's2b_ard_granule'],\n",
    "                      min_gooddata=0.10,\n",
    "                      mask_pixel_quality=True,         \n",
    "                      dask_chunks={},\n",
    "                      **sentinel_data_query)\n",
    "\n",
    "        # Shows an RGB thumbnail of each pass:\n",
    "        s_ds[['nbart_red', 'nbart_green', 'nbart_blue']].isel(time=0).to_array().plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Making an NDWI layer and showing a thumbnail of the output\n",
    "        ds_ndwi = (s_ds.nbart_nir_1 - s_ds.nbart_swir_2) /(s_ds.nbart_nir_1 + s_ds.nbart_swir_2)\n",
    "        s_ds[\"NDWI\"] = ds_ndwi\n",
    "        s_ds['NDWI'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Making the fisher index layer and showing a thumbnail of the output\n",
    "        ds_fisher = 1.7204+(171*s_ds.nbart_green)+(3*s_ds.nbart_red)-(70*s_ds.nbart_nir_1)-(45*s_ds.nbart_swir_2)-(71*s_ds.nbart_swir_3)\n",
    "        s_ds['Fisher'] = ds_fisher  \n",
    "        s_ds['Fisher'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        ds_burnsie = (s_ds.nbart_swir_2 + s_ds.nbart_nir_1 + s_ds.nbart_red)\n",
    "        s_ds['Burnsie'] = ds_burnsie \n",
    "        s_ds['Burnsie'].isel(time=0).plot.imshow(robust=True, figsize=(8, 8))\n",
    "\n",
    "        # Write the layers to a NetCDF, ready for importing\n",
    "        try:\n",
    "            write_dataset_to_netcdf(s_ds, file_name)\n",
    "            \n",
    "        except RuntimeError:\n",
    "            print('***THIS FILE NAME ALREADY EXISTS, PLEASE SAVE YOUR NETCDF FILES TO ANOTHER DIRECTORY***')\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting hydrograph 1: all satellite flyovers on the gauge data:\n",
    "py.plot(fig_all,filename='hydrograph_outputs/all_passes_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting hydrograph 2: satellite passes divided into rising and falling cats with gauge data\n",
    "py.plot(fig_rising_falling,filename='hydrograph_outputs/rising_falling_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting hydrograph 3: satellite passes divided into the \n",
    "# final pass/fail categories with gauge data:\n",
    "py.plot(passing_failing_graph, filename='hydrograph_outputs/pass_fail_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting the dataframe to the csv\n",
    "corrected_master_df.to_csv(\"csv_outputs/all_fly_overs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
